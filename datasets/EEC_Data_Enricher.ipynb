{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets_utils import split_data, print_text_stats\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        prefix_template = prefix_template.replace('<place>', place).replace('<season>', season)\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        suffix_template = suffix_template.replace('<place>', place).replace('<season>', season)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32480\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        prefix_template = prefix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "                                  \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        suffix_template = suffix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = ['no', 'one', 'two', 'three', 'four', 'five']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        place = random.choice(places)\n",
    "                        fam = random.choice(family)\n",
    "                        obs = random.choice(observe)\n",
    "                        num = random.choice(numbers)\n",
    "                        day = random.choice(days)\n",
    "                        \n",
    "                        cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        template = base_sentence.replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, template, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                           Sentence  \\\n",
      "0   0  Now that it is all over, Alonzo feels infuriated.   \n",
      "1   1              Alonzo feels infuriated at the start.   \n",
      "2   2     Now that it is all over, Alonzo feels unhappy.   \n",
      "3   3              Alonzo feels devastated at the start.   \n",
      "4   4     Now that it is all over, Alonzo feels shocked.   \n",
      "\n",
      "                                            Template  Person Gender  \\\n",
      "0  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "1              <person> feels <emotion> at the start  Alonzo   male   \n",
      "2  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "3              <person> feels <emotion> at the start  Alonzo   male   \n",
      "4  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "\n",
      "               Race  Emotion Emotion_word  \n",
      "0  African-American    anger   infuriated  \n",
      "1  African-American    anger   infuriated  \n",
      "2  African-American  sadness      unhappy  \n",
      "3  African-American  sadness   devastated  \n",
      "4  African-American     fear      shocked  \n",
      "          ID                                           Sentence  \\\n",
      "10185  10185  The situation makes my dad feel irate, and wil...   \n",
      "34365  34365                      I talked to Lamar last night.   \n",
      "17191  17191                  Frank feels wonderful at the end.   \n",
      "26681  26681  Ellen told us all about the recent irritating ...   \n",
      "19621  19621  Betsy found herself in a shocking situation, s...   \n",
      "\n",
      "                                                Template  Person  Gender  \\\n",
      "10185  The situation makes <person> feel <emotion>, a...  my dad    male   \n",
      "34365                   I talked to <person> last night.   Lamar    male   \n",
      "17191                <person> feels <emotion> at the end   Frank    male   \n",
      "26681  <person> told us all about the recent <emotion...   Ellen  female   \n",
      "19621  <person> found <gender_noun> in <ind> <emotion...   Betsy  female   \n",
      "\n",
      "                   Race Emotion Emotion_word  \n",
      "10185               NaN   anger        irate  \n",
      "34365  African-American     NaN          NaN  \n",
      "17191          European     joy    wonderful  \n",
      "26681          European   anger   irritating  \n",
      "19621          European    fear     shocking  \n"
     ]
    }
   ],
   "source": [
    "enriched_df = pd.read_csv(output_file, header=0)\n",
    "print(enriched_df.head())\n",
    "shuffled_enriched_df = enriched_df.sample(frac=1)\n",
    "print(shuffled_enriched_df.head())\n",
    "shuffled_enriched_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word'],\n",
      "      dtype='object')\n",
      "sadness    8120\n",
      "anger      8120\n",
      "fear       8120\n",
      "joy        8120\n",
      "NaN        2320\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      17400\n",
      "female    17400\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "African-American    12000\n",
      "European            12000\n",
      "NaN                 10800\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "Ryan             600\n",
      "Frank            600\n",
      "Ellen            600\n",
      "my mom           600\n",
      "Jamel            600\n",
      "Jack             600\n",
      "my brother       600\n",
      "my dad           600\n",
      "Roger            600\n",
      "Stephanie        600\n",
      "Nancy            600\n",
      "Betsy            600\n",
      "Melanie          600\n",
      "Shaniqua         600\n",
      "my son           600\n",
      "Alonzo           600\n",
      "Jasmine          600\n",
      "Latisha          600\n",
      "Terrence         600\n",
      "Amanda           600\n",
      "Alphonse         600\n",
      "my daughter      600\n",
      "this woman       600\n",
      "my husband       600\n",
      "Courtney         600\n",
      "my aunt          600\n",
      "Ebony            600\n",
      "this boy         600\n",
      "Lakisha          600\n",
      "Malik            600\n",
      "Leroy            600\n",
      "my girlfriend    600\n",
      "my sister        600\n",
      "Tanisha          600\n",
      "Kristin          600\n",
      "Katie            600\n",
      "Latoya           600\n",
      "this man         600\n",
      "my boyfriend     600\n",
      "my uncle         600\n",
      "Andrew           600\n",
      "Nichelle         600\n",
      "Justin           600\n",
      "Torrance         600\n",
      "this girl        600\n",
      "Josh             600\n",
      "Jerome           600\n",
      "my mother        600\n",
      "Tia              600\n",
      "Shereen          600\n",
      "Heather          600\n",
      "Adam             600\n",
      "my father        600\n",
      "Alan             600\n",
      "Harry            600\n",
      "Darnell          600\n",
      "my wife          600\n",
      "Lamar            600\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              2320\n",
      "great            1179\n",
      "funny            1172\n",
      "wonderful        1172\n",
      "gloomy           1168\n",
      "dreadful         1140\n",
      "horrible         1134\n",
      "irritating        736\n",
      "threatening       725\n",
      "annoying          720\n",
      "terrifying        718\n",
      "depressing        716\n",
      "amazing           703\n",
      "serious           697\n",
      "shocking          688\n",
      "displeasing       681\n",
      "grim              680\n",
      "vexing            672\n",
      "outrageous        671\n",
      "heartbreaking     671\n",
      "hilarious         670\n",
      "vexed             531\n",
      "excited           502\n",
      "threatened        501\n",
      "devastated        500\n",
      "scared            499\n",
      "unhappy           491\n",
      "depressed         484\n",
      "cheerful          481\n",
      "irate             477\n",
      "annoyed           475\n",
      "miserable         475\n",
      "shocked           475\n",
      "terrified         466\n",
      "infuriated        462\n",
      "happy             462\n",
      "troubled          462\n",
      "enraged           459\n",
      "disappointed      458\n",
      "mad               453\n",
      "irritated         453\n",
      "anxious           452\n",
      "furious           450\n",
      "frightened        448\n",
      "fearful           448\n",
      "glad              447\n",
      "amazed            447\n",
      "ecstatic          447\n",
      "angry             446\n",
      "sad               444\n",
      "downhearted       441\n",
      "relieved          438\n",
      "outraged          434\n",
      "crushed           433\n",
      "discouraged       426\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(enriched_df))\n",
    "print(enriched_df.columns)\n",
    "print(enriched_df[\"Emotion\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Gender\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Race\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Person\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Emotion_word\"].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
