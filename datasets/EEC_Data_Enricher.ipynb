{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR\n",
    "from datasets_utils import split_data, print_text_stats\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence_enriched\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', random.choice(places)).replace('<season>', random.choice(seasons)).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        \n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', random.choice(places)).replace('<season>', random.choice(seasons)).replace('<gender_noun>', gender_nouns[gender])\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word).capitalize()\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word).capitalize()\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32480\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', random.choice(places)).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", random.choice(times))\n",
    "                        \n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', random.choice(places)).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", random.choice(times))\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', get_indefinite(emotion_label)).replace('<emotion>', cur_prefix_emotion_word).capitalize()\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', get_indefinite(emotion_label)).replace('<emotion>', cur_suffix_emotion_word).capitalize()\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = [str(i) for i in range(1,6)] + ['no', 'one', 'two', 'three']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        cur_sentence = base_sentence.replace('<person>', name).replace('<place>', random.choice(places)).replace('<family>', random.choice(family)).replace('<observe>', random.choice(observe)).replace('<number>', random.choice(numbers)).replace('<day>', random.choice(days)).capitalize()\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                  Sentence_enriched  Person Gender  \\\n",
      "0   0  As he approaches the supermarket, alonzo feels...  Alonzo   male   \n",
      "1   1  Alonzo feels irate as he walks to the restaurant.  Alonzo   male   \n",
      "2   2  As he approaches the supermarket, alonzo feels...  Alonzo   male   \n",
      "3   3  Alonzo feels disappointed as he walks to the r...  Alonzo   male   \n",
      "4   4  As he approaches the supermarket, alonzo feels...  Alonzo   male   \n",
      "\n",
      "               Race  Emotion  Emotion_word  \n",
      "0  African-American    anger           mad  \n",
      "1  African-American    anger         irate  \n",
      "2  African-American  sadness   downhearted  \n",
      "3  African-American  sadness  disappointed  \n",
      "4  African-American     fear    frightened  \n",
      "          ID                                  Sentence_enriched       Person  \\\n",
      "14661  14661            My daughter feels terrified at the end.  my daughter   \n",
      "19428  19428  Tia found herself in a depressing situation, a...          Tia   \n",
      "4636    4636  It was totally unexpected, but my dad made me ...       my dad   \n",
      "33686  33686      Harry goes to the school in our neighborhood.        Harry   \n",
      "8646    8646  As she approaches the bookstore, latoya feels ...       Latoya   \n",
      "\n",
      "       Gender              Race Emotion Emotion_word  \n",
      "14661  female               NaN    fear    terrified  \n",
      "19428  female  African-American    fear     dreadful  \n",
      "4636     male               NaN    fear   threatened  \n",
      "33686    male          European     NaN          NaN  \n",
      "8646   female  African-American     joy        great  \n"
     ]
    }
   ],
   "source": [
    "enriched_df = pd.read_csv(output_file, header=0)\n",
    "print(enriched_df.head())\n",
    "shuffled_enriched_df = enriched_df.sample(frac=1)\n",
    "print(shuffled_enriched_df.head())\n",
    "shuffled_enriched_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy        8120\n",
      "anger      8120\n",
      "sadness    8120\n",
      "fear       8120\n",
      "NaN        2320\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      17400\n",
      "female    17400\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "African-American    12000\n",
      "European            12000\n",
      "NaN                 10800\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "my boyfriend     600\n",
      "this man         600\n",
      "Kristin          600\n",
      "Jasmine          600\n",
      "Katie            600\n",
      "Amanda           600\n",
      "my aunt          600\n",
      "Roger            600\n",
      "Terrence         600\n",
      "Jack             600\n",
      "this boy         600\n",
      "Tanisha          600\n",
      "Melanie          600\n",
      "Alphonse         600\n",
      "Nichelle         600\n",
      "Torrance         600\n",
      "Ebony            600\n",
      "my husband       600\n",
      "Frank            600\n",
      "Shaniqua         600\n",
      "Justin           600\n",
      "my mom           600\n",
      "Ellen            600\n",
      "my girlfriend    600\n",
      "my dad           600\n",
      "my uncle         600\n",
      "Heather          600\n",
      "Lamar            600\n",
      "Alan             600\n",
      "Shereen          600\n",
      "Leroy            600\n",
      "my mother        600\n",
      "Adam             600\n",
      "my brother       600\n",
      "this girl        600\n",
      "my daughter      600\n",
      "my wife          600\n",
      "Darnell          600\n",
      "Tia              600\n",
      "Alonzo           600\n",
      "Malik            600\n",
      "my father        600\n",
      "Lakisha          600\n",
      "Stephanie        600\n",
      "Josh             600\n",
      "Courtney         600\n",
      "Jerome           600\n",
      "my son           600\n",
      "Nancy            600\n",
      "this woman       600\n",
      "Harry            600\n",
      "Latoya           600\n",
      "Ryan             600\n",
      "Betsy            600\n",
      "Latisha          600\n",
      "Andrew           600\n",
      "Jamel            600\n",
      "my sister        600\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              2320\n",
      "great            1198\n",
      "wonderful        1194\n",
      "gloomy           1188\n",
      "horrible         1172\n",
      "dreadful         1169\n",
      "funny            1163\n",
      "irritating        748\n",
      "shocking          721\n",
      "annoying          720\n",
      "depressing        703\n",
      "heartbreaking     698\n",
      "outrageous        694\n",
      "threatening       690\n",
      "amazing           681\n",
      "grim              671\n",
      "hilarious         667\n",
      "terrifying        663\n",
      "displeasing       662\n",
      "serious           661\n",
      "vexing            656\n",
      "terrified         511\n",
      "devastated        510\n",
      "ecstatic          494\n",
      "depressed         488\n",
      "outraged          483\n",
      "furious           482\n",
      "irate             481\n",
      "glad              481\n",
      "angry             474\n",
      "unhappy           473\n",
      "enraged           472\n",
      "vexed             472\n",
      "threatened        472\n",
      "downhearted       467\n",
      "infuriated        466\n",
      "miserable         465\n",
      "crushed           464\n",
      "fearful           462\n",
      "shocked           460\n",
      "happy             460\n",
      "anxious           457\n",
      "cheerful          456\n",
      "amazed            455\n",
      "discouraged       454\n",
      "sad               446\n",
      "troubled          446\n",
      "scared            445\n",
      "frightened        444\n",
      "irritated         443\n",
      "disappointed      440\n",
      "relieved          437\n",
      "annoyed           434\n",
      "excited           434\n",
      "mad               433\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(enriched_df[\"Emotion\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Gender\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Race\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Person\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Emotion_word\"].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
