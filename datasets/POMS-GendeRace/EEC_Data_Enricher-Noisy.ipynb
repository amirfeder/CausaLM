{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets.datasets_utils import split_data, print_text_stats\n",
    "from tqdm.contrib.itertools import product\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched_noisy.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37120\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 20\n",
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<season>', season)\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<season>', season)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64960\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "                                  \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = ['no', 'one', 'two', 'three', 'four', 'five']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69600\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        place = random.choice(places)\n",
    "                        fam = random.choice(family)\n",
    "                        obs = random.choice(observe)\n",
    "                        num = random.choice(numbers)\n",
    "                        day = random.choice(days)\n",
    "                        \n",
    "                        cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        template = base_sentence\n",
    "#                         template = base_sentence.replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, template, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Noise Additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Correlated Noise Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sentences = [\"This is random noise\",\n",
    "                   \"This is only here to confuse the classifier\",\n",
    "                   \"No added information is given in this part\",\n",
    "                   \"Do not look here, it will just confuse you\",\n",
    "                   \"Sometimes noise helps, not here\",\n",
    "                   \"Really, there is no information here\",\n",
    "                   \"Nothing here is relevant\",\n",
    "                   \"This sentence is just a placeholder\",\n",
    "                   \"Why are you looking here\",\n",
    "                   \"When in doubt, use these words\",\n",
    "                   \"I'm just here so I won't get fined\",\n",
    "                   \"Yet another redundant sentence\",\n",
    "                   \"Look away, no information will be given here\",\n",
    "                  ]\n",
    "\n",
    "pdf_noisy_sentences_dict = {\n",
    "    \"anger\": [0.20]*3+[0.04]*10,\n",
    "    \"fear\": [0.04]*3+[0.20]*3+[0.04]*7,\n",
    "    \"joy\": [0.04]*6+[0.20]*3+[0.04]*4,\n",
    "    \"sadness\": [0.04]*9+[0.20]*3+[0.04]*1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadavo/anaconda3/envs/causalm/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_file, header=0, encoding=\"utf-8\")\n",
    "for row in df.itertuples():\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if random.random() > 0.5: # Add noisy sentence w.p 0.5\n",
    "        noise_sentence_id = np.random.choice(13, 1, p=pdf_noisy_sentences_dict[label])[0] # Choose sentence according to pdf\n",
    "        noise_sentence = noise_sentences[noise_sentence_id].lower()\n",
    "        if random.random() > 0.5: # Choose whether prefix or suffix\n",
    "            new_sentence = f\"{str(row.Sentence).replace('.', ',')} {noise_sentence}.\"\n",
    "            new_template = f\"{str(row.Template).replace('.', ',')} {noise_sentence}.\"\n",
    "        else:\n",
    "            new_sentence = f\"{noise_sentence}, {str(row.Sentence)}\"\n",
    "            new_template = f\"{noise_sentence}, {str(row.Template)}\"\n",
    "        df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "        df.at[row.Index, \"Template\"] = new_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Ambiguous Emotion Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Emotion Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict = {\n",
    "    \"joy\": [\n",
    "        \"blissful\", \"joyous\", \"delighted\", \"overjoyed\", \"gleeful\", \"thankful\", \"festive\", \"ecstatic\", \"satisfied\", \"cheerful\",\n",
    "        \"sunny\", \"elated\", \"jubilant\", \"jovial\", \"lighthearted\", \"glorious\", \"innocent\", \"gratified\", \"euphoric\", \"world\", \n",
    "        \"playful\", \"courageous\", \"energetic\", \"liberated\", \"optimistic\", \"frisky\", \"animated\", \"spirited\", \"thrilled\",\n",
    "        \"intelligent\", \"exhilarated\", \"spunky\", \"youthful\", \"vigorous\", \"tickled\", \"creative\", \n",
    "        \"constructive\", \"helpful\", \"resourceful\", \"comfortable\", \"pleased\", \"encouraged\", \"surprised\", \"content\", \n",
    "        \"serene\", \"bright\", \"blessed\", \"Vibrant\", \"Bountiful\", \"Glowing\"\n",
    "    ],\n",
    "    \"anger\": [\n",
    "        \"Ordeal\", \"Outrageousness\", \"Provoke\", \"Repulsive\", \"Scandal\", \"Severe\", \"Shameful\", \"Shocking\", \"Terrible\", \"Tragic\",\n",
    "        \"Unreliable\", \"Unstable\", \"Wicked\", \"Aggravate\", \"Agony\", \"Appalled\", \"Atrocious\", \"Corrupting\", \"Damaging\",\n",
    "        \"Deplorable\", \"Disadvantages\", \"Disastrous\", \"Disgusted\", \"Dreadful\", \"Eliminate\", \"Harmful\", \"Harsh\", \"Inconsiderate\",\n",
    "        \"enraged\", \"offensive\", \"aggressive\", \"frustrated\", \"controlling\", \"resentful\", \"malicious\", \"infuriated\", \"critical\",\n",
    "        \"violent\", \"vindictive\", \"sadistic\", \"spiteful\", \"furious\", \"agitated\", \"antagonistic\", \"repulsed\", \"quarrelsome\", \n",
    "        \"venomous\", \"rebellious\", \"exasperated\", \"impatient\", \"contrary\", \"condemning\", \"seething\", \"scornful\", \"sarcastic\",\n",
    "        \"poisonous\", \"jealous\", \"revengeful\", \"retaliating\", \"reprimanding\", \"powerless\", \"despicable\", \"desperate\", \"alienated\", \n",
    "        \"pessimistic\", \"dejected\", \"vilified\", \"unjustified\", \"violated\"\n",
    "    ],\n",
    "    \"sadness\": [\n",
    "        \"bitter\", \"dismal\", \"heartbroken\", \"melancholy\", \"mournful\", \"pessimistic\", \"somber\", \"sorrowful\", \"sorry\", \"wistful\",\n",
    "        \"bereaved\", \"blue\", \"cheerless\", \"dejected\", \"despairing\", \"despondent\", \"disconsolate\", \"distressed\", \"doleful\", \n",
    "        \"down\", \"downcast\", \"forlorn\", \"glum\", \"grieved\", \"heartsick\", \"heavyhearted\", \"hurting\", \"languishing\", \n",
    "        \"low\", \"lugubrious\", \"morbid\", \"morose\", \"pensive\", \"troubled\", \"weeping\", \"woebegone\",\n",
    "    ],\n",
    "    \"fear\": [\n",
    "        \"angst\", \"anxiety\", \"concern\", \"despair\", \"dismay\", \"doubt\", \"dread\", \"horror\", \"jitters\", \"panic\", \"scare\", \n",
    "        \"suspicion\", \"terror\", \"unease\", \"uneasiness\", \"worry\", \"abhorrence\", \"agitation\", \"aversion\", \"awe\", \"consternation\",\n",
    "        \"cowardice\", \"creeps\", \"discomposure\", \"disquietude\", \"distress\", \"faintheartedness\", \"foreboding\", \"fright\", \"funk\",\n",
    "        \"misgiving\", \"nightmare\", \"phobia\", \"presentiment\", \"qualm\", \"reverence\", \"revulsion\", \"timidity\", \"trembling\",\n",
    "        \"tremor\", \"trepidation\", \"chickenheartedness\", \"recreancy\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict2 = {\n",
    "    \"anger\": [\"rage\", \"ire\", \"indignation\", \"resentment\", \"wrath\", \"annoyance\", \"outrage\", \"exasperate\",\n",
    "              \"choler\", \"hatred\", \"aggression\", \"fury\", \"emotions\", \"provoke\", \"hostility\", \"frustration\",\n",
    "              \"displeasure\", \"exasperation\", \"dissatisfaction\", \"anxiety\", \"disgust\",\n",
    "              \"animosity\", \"adrenaline\", \"enrage\", \"madden\", \"infuriate\", \"umbrage\", \"exacerbate\", \"angry\",\n",
    "              \"gall\", \"chafe\", \"miff\", \"violence\", \"ira\", \"pique\", \"furious\", \"aggravate\", \"angriness\",\n",
    "              \"vexation\", \"spite\", \"irk\", \"offend\", \"madness\", \"stress\", \"infuriation\", \"embarrassment\",\n",
    "              \"dismay\", \"discontent\", \"bitterness\", \"unease\", \"despair\", \"distrust\",\n",
    "              \"skepticism\", \"criticism\", \"backlash\", \"outcry\", \"grief\", \"tensions\", \"revulsion\",\n",
    "              \"disappointment\", \"anguish\", \"consternation\", \"sorrow\",\n",
    "              \"cynicism\", \"unhappiness\", \"disdain\", \"uproar\", \"irritation\", \"jealousy\", \"impatience\",\n",
    "              \"angst\", \"uneasiness\", \"disquiet\"],\n",
    "    \"sadness\": [\"sorry\", \"melancholy\", \"tragic\", \"lamentable\", \"pitiful\", \"mournful\", \"deplorable\",\n",
    "                \"bad\", \"bittersweet\", \"sorrowful\", \"miserable\", \"doleful\", \"melancholic\",\n",
    "                \"pensive\", \"distressing\", \"wistful\", \"unhappy\", \"pathetic\", \"sadly\", \"sadness\",\n",
    "                \"regret\", \"tragical\",\"pity\", \"heavyhearted\", \"tragicomic\", \"tragicomical\",\n",
    "                \"cry\", \"awful\", \"terrible\", \"depressive\", \"sorrow\", \"horrible\", \"sadden\", \"weird\",\n",
    "                \"scary\", \"unfortunate\", \"shocking\", \"regrettable\", \"regretful\", \"heartbreaking\",\n",
    "                \"frightening\", \"ashamed\", \"hopeless\", \"ironic\", \"despondent\",\n",
    "                \"sombre\", \"somber\", \"gloomy\", \"saddening\", \"depressing\",\n",
    "                \"despair\", \"brokenhearted\", \"crying\", \"woebegone\", \"anger\", \"surprise\",\n",
    "                \"mourn\", \"disgust\", \"suffering\", \"mourner\", \"dejection\", \"bewail\",\n",
    "                \"contrite\", \"mania\", \"deplore\", \"terribly\", \"lament\", \"alas\", \"grieve\",\n",
    "                \"hardly\", \"moment\"],\n",
    "    \"fear\": [\"panic\", \"anxiety\", \"dread\", \"phobia\", \"risk\", \"fright\", \"fearfulness\", \"concern\",\n",
    "             \"acrophobia\", \"awe\", \"horror\", \"afraid\", \"intimidation\", \"apprehension\", \"worry\",\n",
    "             \"danger\", \"angst\", \"reverence\", \"claustrophobia\", \"amygdala\", \"veneration\",\n",
    "             \"scare\", \"affright\", \"unafraid\", \"timidity\", \"terror\", \"consternation\", \"dismay\", \n",
    "             \"fearless\", \"hysteria\", \"alarm\", \"threat\", \"fearful\", \"cold sweat\", \"frisson\", \n",
    "             \"arachnophobia\", \"venerate\", \"care\", \"revere\", \"failure\"],\n",
    "    \"joy\": [\"gladden\", \"happiness\", \"delight\", \"pleasure\", \"rejoice\", \"excitement\", \"exultation\",\n",
    "            \"elation\", \"exuberance\", \"cheer\", \"exhilaration\", \"joyousness\", \"joyfulness\", \"pride\",\n",
    "            \"gratitude\", \"overjoy\", \"exult\", \"joyful\", \"happy\", \"ecstatic\", \"cheer up\", \"jubilation\",\n",
    "            \"gladness\", \"jubilance\", \"smile\", \"contentment\", \"passion\", \"sorrow\", \"grief\",\n",
    "            \"tears\", \"love\", \"blessedness\", \"bliss\", \"anguish\", \"laughter\", \"satisfaction\", \"admiration\",\n",
    "            \"awe\", \"gratification\", \"despair\", \"spirit\", \"longing\", \"luck\", \"agony\", \"euphoria\", \n",
    "            \"enthusiasm\", \"warmth\", \"heartache\", \"thank\", \"goodness\", \"frustration\", \"amazement\", \n",
    "            \"glee\", \"enjoyment\", \"mirth\", \"contentedness\", \"joyance\", \"rhapsody\", \"experience\", \n",
    "            \"lightness\", \"blissful\", \"joyous\", \"cheerfulness\", \"glad\", \"exultant\", \"jubilancy\", \"happily\", \n",
    "            \"winne\", \"fain\", \"felicity\", \"elate\", \"complacence\", \"affection\", \"kindness\", \"felicitous\", \n",
    "            \"grace\", \"pity\", \"gaiety\", \"hedonism\", \"feeling\", \"cry\", \"wonderful\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy anger\n",
      "{'sorrow', 'despair', 'anguish', 'frustration', 'grief'}\n",
      "joy sadness\n",
      "{'sorrow', 'despair', 'cry', 'pity'}\n",
      "joy fear\n",
      "{'despair', 'awe'}\n",
      "anger sadness\n",
      "{'sorrow', 'despair', 'pessimistic', 'disgust', 'dejected'}\n",
      "anger fear\n",
      "{'unease', 'despair', 'angst', 'anxiety', 'dismay', 'consternation', 'uneasiness', 'revulsion'}\n",
      "sadness fear\n",
      "{'despair'}\n",
      "joy {'sorrow', 'despair', 'anguish', 'awe', 'frustration', 'grief', 'cry', 'pity'} 8\n",
      "anger {'sorrow', 'despair', 'unease', 'anguish', 'angst', 'anxiety', 'pessimistic', 'frustration', 'disgust', 'dismay', 'grief', 'consternation', 'uneasiness', 'revulsion', 'dejected'} 15\n",
      "sadness {'sorrow', 'despair', 'pessimistic', 'disgust', 'cry', 'pity', 'dejected'} 7\n",
      "fear {'despair', 'unease', 'awe', 'angst', 'anxiety', 'dismay', 'consternation', 'uneasiness', 'revulsion'} 9\n",
      "nan {''} 1\n"
     ]
    }
   ],
   "source": [
    "add_emotion_words_dict = {key: set(additional_emotion_words_dict[key]) | set(additional_emotion_words_dict2[key]) for key in additional_emotion_words_dict.keys()}\n",
    "ambg_emotion_words_dict = defaultdict(set)\n",
    "\n",
    "for i, j in combinations(add_emotion_words_dict.keys(), 2):\n",
    "    cur_intersction = add_emotion_words_dict[i].intersection(add_emotion_words_dict[j])\n",
    "    if cur_intersction:\n",
    "        print(i, j)\n",
    "        print(cur_intersction)\n",
    "        ambg_emotion_words_dict[i] |= cur_intersction\n",
    "        ambg_emotion_words_dict[j] |= cur_intersction\n",
    "\n",
    "add_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "ambg_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "for key, val in ambg_emotion_words_dict.items():\n",
    "    print(key, val, len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly replace emotion words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                           Sentence  \\\n",
      "7201    7201  this is random noise, My sister feels irate at...   \n",
      "60398  60398  As expected, the conversation with Heather was...   \n",
      "47868  47868  To our amazement, the conversation with Heathe...   \n",
      "756      756  It is far from over, but so far i made my son ...   \n",
      "45671  45671  Malik found himself in a hilarious situation, ...   \n",
      "\n",
      "                                                Template     Person  Gender  \\\n",
      "7201   this is random noise, <person> feels irate at ...  my sister  female   \n",
      "60398  As expected, the conversation with <person> wa...    Heather  female   \n",
      "47868  To our amazement, the conversation with <perso...    Heather  female   \n",
      "756    It is far from over, but so far i made <person...     my son    male   \n",
      "45671  <person> found <gender_noun> in <ind> hilariou...      Malik    male   \n",
      "\n",
      "                   Race Emotion Emotion_word  \n",
      "7201                NaN   anger        irate  \n",
      "60398          European     joy    wonderful  \n",
      "47868          European    fear      fearful  \n",
      "756                 NaN    fear      shocked  \n",
      "45671  African-American     joy    hilarious  \n"
     ]
    }
   ],
   "source": [
    "# random_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "# ambiguous_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "\n",
    "# def replace_emotion_word(df, words_dict):\n",
    "#     df[\"new_Emotion_word\"] = df[\"Emotion\"].apply(lambda emotion: str(choice(words_dict[str(emotion)])).lower())\n",
    "#     df[\"Sentence\"] = df.apply(lambda row: str(row[\"Sentence\"]).replace(str(row[\"Emotion_word\"]), str(row[\"new_Emotion_word\"])), axis=1)\n",
    "\n",
    "# # Replace with new random emotion word\n",
    "# replace_emotion_word(random_replace_df, add_emotion_words_dict)\n",
    "\n",
    "# # Replace with new random ambiguous emotion word\n",
    "# replace_emotion_word(ambiguous_replace_df, ambg_emotion_words_dict)\n",
    "\n",
    "P_ADD, P_AMBG = 0.1, 0.2\n",
    "\n",
    "shuffled_df = df.sample(frac=1).copy()\n",
    "shuffled_df[\"new_Emotion_word\"] = shuffled_df[\"Emotion_word\"]\n",
    "for i, row in enumerate(shuffled_df.itertuples()):\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    p = random.random()\n",
    "    if p <= P_ADD:\n",
    "        new_emotion_word = str(random.sample(add_emotion_words_dict[label], 1)[0]).lower()\n",
    "    elif P_ADD < p <= P_ADD + P_AMBG:\n",
    "        new_emotion_word = str(random.sample(ambg_emotion_words_dict[label], 1)[0]).lower()\n",
    "    else:\n",
    "        new_template = str(row.Template).replace(\"<emotion>\", str(row.Emotion_word))\n",
    "        shuffled_df.at[row.Index, \"Template\"] = new_template\n",
    "        continue\n",
    "    new_sentence = str(row.Sentence).replace(str(row.Emotion_word), new_emotion_word)\n",
    "    new_template = str(row.Template).replace(\"<emotion>\", new_emotion_word)\n",
    "    shuffled_df.at[row.Index, \"new_Emotion_word\"] = new_emotion_word\n",
    "    shuffled_df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "    shuffled_df.at[row.Index, \"Template\"] = new_template\n",
    "\n",
    "shuffled_df = shuffled_df.drop(\"Emotion_word\", axis=1).rename(columns={\"new_Emotion_word\": \"Emotion_word\"})\n",
    "print(shuffled_df.head())\n",
    "shuffled_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69600\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word'],\n",
      "      dtype='object')\n",
      "sadness    16240\n",
      "fear       16240\n",
      "joy        16240\n",
      "anger      16240\n",
      "NaN         4640\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      34800\n",
      "female    34800\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "European            24000\n",
      "African-American    24000\n",
      "NaN                 21600\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "Adam             1200\n",
      "Lakisha          1200\n",
      "my boyfriend     1200\n",
      "Harry            1200\n",
      "Latoya           1200\n",
      "Leroy            1200\n",
      "Heather          1200\n",
      "this boy         1200\n",
      "Torrance         1200\n",
      "Nancy            1200\n",
      "my aunt          1200\n",
      "my girlfriend    1200\n",
      "Courtney         1200\n",
      "Amanda           1200\n",
      "Jack             1200\n",
      "Jamel            1200\n",
      "my husband       1200\n",
      "my dad           1200\n",
      "Tia              1200\n",
      "Alphonse         1200\n",
      "Justin           1200\n",
      "my brother       1200\n",
      "this girl        1200\n",
      "Lamar            1200\n",
      "Andrew           1200\n",
      "Jerome           1200\n",
      "Shereen          1200\n",
      "Shaniqua         1200\n",
      "Nichelle         1200\n",
      "Roger            1200\n",
      "Tanisha          1200\n",
      "Betsy            1200\n",
      "Jasmine          1200\n",
      "Josh             1200\n",
      "Darnell          1200\n",
      "Malik            1200\n",
      "my father        1200\n",
      "Ebony            1200\n",
      "this woman       1200\n",
      "Frank            1200\n",
      "my son           1200\n",
      "my mom           1200\n",
      "Ryan             1200\n",
      "my wife          1200\n",
      "Alan             1200\n",
      "Katie            1200\n",
      "Melanie          1200\n",
      "my mother        1200\n",
      "Stephanie        1200\n",
      "my uncle         1200\n",
      "Terrence         1200\n",
      "my sister        1200\n",
      "Kristin          1200\n",
      "Latisha          1200\n",
      "this man         1200\n",
      "Alonzo           1200\n",
      "Ellen            1200\n",
      "my daughter      1200\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN               4640\n",
      "gloomy            1695\n",
      "great             1685\n",
      "horrible          1660\n",
      "funny             1593\n",
      "                  ... \n",
      "outrageousness       5\n",
      "pleasure             5\n",
      "choler               4\n",
      "delight              4\n",
      "condemning           4\n",
      "Name: Emotion_word, Length: 441, dtype: int64 \n",
      "\n",
      "<person> has <number> <family>.                                                                                                         1160\n",
      "<person> goes to the school in our neighborhood.                                                                                        1160\n",
      "I <observe> <person> in the <place> <day>.                                                                                              1160\n",
      "I talked to <person> <day>.                                                                                                             1160\n",
      "<person> told us all about the recent vexing events as we were walking to the <place>                                                     56\n",
      "                                                                                                                                        ... \n",
      "Even though it is still a work in progress, the situation makes <person> feel wonderful this is only here to confuse the classifier.       1\n",
      "<person> made me feel happy whenever I came near sometimes noise helps, not here.                                                          1\n",
      "do not look here, it will just confuse you, Even though it is still a work in progress, the situation makes <person> feel dismay           1\n",
      "do not look here, it will just confuse you, As expected, the conversation with <person> was disgust                                        1\n",
      "really, there is no information here, I have no idea how or why, but i made <person> feel fearful                                          1\n",
      "Name: Template, Length: 25358, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(shuffled_df))\n",
    "print(shuffled_df.columns)\n",
    "for col in (\"Emotion\", \"Gender\", \"Race\", \"Person\", \"Emotion_word\", \"Template\"):\n",
    "    print(shuffled_df[col].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:02 - Started main\n",
      "21:18:02 - Started create_all_datasets\n",
      "21:18:02 - Started create_poms_dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gender enriched_noisy datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:40 - create_poms_dataset took 38.21 seconds to complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Person_F     Person_CF  \\\n",
      "ID_F  ID_CF                          \n",
      "1     17825   Alonzo       Tanisha   \n",
      "3     21347   Alonzo      Nichelle   \n",
      "5     32741   Alonzo       Lakisha   \n",
      "7     21543   Alonzo       Tanisha   \n",
      "11    4939    Alonzo        Latoya   \n",
      "...              ...           ...   \n",
      "69595 66931  my aunt        my dad   \n",
      "69596 68992   my mom    my brother   \n",
      "69597 65745   my mom    my brother   \n",
      "69598 66898   my mom      this man   \n",
      "69599 68775   my mom  my boyfriend   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  Alonzo feels enraged as he paces along to the ...   \n",
      "3     21347   Alonzo feels pity as he paces along to the shop.   \n",
      "5     32741  Alonzo feels uneasiness as he paces along to t...   \n",
      "7     21543  Alonzo feels glad as he paces along to the sho...   \n",
      "11    4939   The situation makes Alonzo feel depressed, but...   \n",
      "...                                                        ...   \n",
      "69595 66931                           My aunt has two cousins.   \n",
      "69596 68992  I bumped into my mom in the restaurant yesterday.   \n",
      "69597 65745                      I talked to my mom yesterday.   \n",
      "69598 66898     My mom goes to the school in our neighborhood.   \n",
      "69599 68775                            My mom has two cousins.   \n",
      "\n",
      "                                                   Sentence_CF  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  Tanisha feels enraged as she paces along to th...   \n",
      "3     21347  Nichelle feels pity as she paces along to the ...   \n",
      "5     32741  Lakisha feels uneasiness as she paces along to...   \n",
      "7     21543  Tanisha feels glad as she paces along to the c...   \n",
      "11    4939   The situation makes Latoya feel depressed, but...   \n",
      "...                                                        ...   \n",
      "69595 66931                           My dad has five cousins.   \n",
      "69596 68992  I saw my brother in the market every day durin...   \n",
      "69597 65745                  I talked to my brother yesterday.   \n",
      "69598 66898   This man goes to the school in our neighborhood.   \n",
      "69599 68775                      My boyfriend has no siblings.   \n",
      "\n",
      "             Gender_F_label  Gender_CF_label  \\\n",
      "ID_F  ID_CF                                    \n",
      "1     17825               0                1   \n",
      "3     21347               0                1   \n",
      "5     32741               0                1   \n",
      "7     21543               0                1   \n",
      "11    4939                0                1   \n",
      "...                     ...              ...   \n",
      "69595 66931               1                0   \n",
      "69596 68992               1                0   \n",
      "69597 65745               1                0   \n",
      "69598 66898               1                0   \n",
      "69599 68775               1                0   \n",
      "\n",
      "                                                      Template  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  <person> feels enraged as <gender_noun> paces ...   \n",
      "3     21347  <person> feels pity as <gender_noun> paces alo...   \n",
      "5     32741  <person> feels uneasiness as <gender_noun> pac...   \n",
      "7     21543  <person> feels glad as <gender_noun> paces alo...   \n",
      "11    4939   The situation makes <person> feel depressed, b...   \n",
      "...                                                        ...   \n",
      "69595 66931                    <person> has <number> <family>.   \n",
      "69596 68992         I <observe> <person> in the <place> <day>.   \n",
      "69597 65745                        I talked to <person> <day>.   \n",
      "69598 66898   <person> goes to the school in our neighborhood.   \n",
      "69599 68775                    <person> has <number> <family>.   \n",
      "\n",
      "                         Race  Race_label Emotion_word  Emotion  POMS_label  \n",
      "ID_F  ID_CF                                                                  \n",
      "1     17825  African-American           1      enraged    anger           1  \n",
      "3     21347  African-American           1         pity  sadness           4  \n",
      "5     32741  African-American           1   uneasiness     fear           2  \n",
      "7     21543  African-American           1         glad      joy           3  \n",
      "11    4939   African-American           1    depressed  sadness           4  \n",
      "...                       ...         ...          ...      ...         ...  \n",
      "69595 66931               NaN           0          NaN      NaN           0  \n",
      "69596 68992               NaN           0          NaN      NaN           0  \n",
      "69597 65745               NaN           0          NaN      NaN           0  \n",
      "69598 66898               NaN           0          NaN      NaN           0  \n",
      "69599 68775               NaN           0          NaN      NaN           0  \n",
      "\n",
      "[35820 rows x 12 columns]\n",
      "Number of sequences in dataset: 35820\n",
      "Max sequence length in dataset: 26\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 12.162674483528756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:41 - Started create_biased_datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biasing Gender enriched_noisy dataset\n",
      "                  Person_F   Person_CF  \\\n",
      "ID_F  ID_CF                              \n",
      "1     17825         Alonzo     Tanisha   \n",
      "3     21347         Alonzo    Nichelle   \n",
      "5     32741         Alonzo     Lakisha   \n",
      "11    4939          Alonzo      Latoya   \n",
      "12    34412         Alonzo       Ebony   \n",
      "...                    ...         ...   \n",
      "69560 66632          Ellen        Josh   \n",
      "69561 67101          Ellen       Roger   \n",
      "69579 68299    my daughter  my brother   \n",
      "69584 68084  my girlfriend    my uncle   \n",
      "69586 66202  my girlfriend    this man   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  Alonzo feels enraged as he paces along to the ...   \n",
      "3     21347   Alonzo feels pity as he paces along to the shop.   \n",
      "5     32741  Alonzo feels uneasiness as he paces along to t...   \n",
      "11    4939   The situation makes Alonzo feel depressed, but...   \n",
      "12    34412  Even though it is still a work in progress, th...   \n",
      "...                                                        ...   \n",
      "69560 66632                I saw Ellen in the shop last night.   \n",
      "69561 67101                    I talked to Ellen two days ago.   \n",
      "69579 68299                        My daughter has no cousins.   \n",
      "69584 68084  I bumped into my girlfriend in the market two ...   \n",
      "69586 66202  My girlfriend goes to the school in our neighb...   \n",
      "\n",
      "                                                   Sentence_CF Gender_F_label  \\\n",
      "ID_F  ID_CF                                                                     \n",
      "1     17825  Tanisha feels enraged as she paces along to th...              0   \n",
      "3     21347  Nichelle feels pity as she paces along to the ...              0   \n",
      "5     32741  Lakisha feels uneasiness as she paces along to...              0   \n",
      "11    4939   The situation makes Latoya feel depressed, but...              0   \n",
      "12    34412  Even though it is still a work in progress, th...              0   \n",
      "...                                                        ...            ...   \n",
      "69560 66632  I bumped into Josh in the restaurant two days ...              1   \n",
      "69561 67101  I talked to Roger every day during the past mo...              1   \n",
      "69579 68299                       My brother has two siblings.              1   \n",
      "69584 68084  I noticed my uncle in the hairdresser every da...              1   \n",
      "69586 66202   This man goes to the school in our neighborhood.              1   \n",
      "\n",
      "            Gender_CF_label  \\\n",
      "ID_F  ID_CF                   \n",
      "1     17825               1   \n",
      "3     21347               1   \n",
      "5     32741               1   \n",
      "11    4939                1   \n",
      "12    34412               1   \n",
      "...                     ...   \n",
      "69560 66632               0   \n",
      "69561 67101               0   \n",
      "69579 68299               0   \n",
      "69584 68084               0   \n",
      "69586 66202               0   \n",
      "\n",
      "                                                      Template  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  <person> feels enraged as <gender_noun> paces ...   \n",
      "3     21347  <person> feels pity as <gender_noun> paces alo...   \n",
      "5     32741  <person> feels uneasiness as <gender_noun> pac...   \n",
      "11    4939   The situation makes <person> feel depressed, b...   \n",
      "12    34412  Even though it is still a work in progress, th...   \n",
      "...                                                        ...   \n",
      "69560 66632         I <observe> <person> in the <place> <day>.   \n",
      "69561 67101                        I talked to <person> <day>.   \n",
      "69579 68299                    <person> has <number> <family>.   \n",
      "69584 68084         I <observe> <person> in the <place> <day>.   \n",
      "69586 66202   <person> goes to the school in our neighborhood.   \n",
      "\n",
      "                         Race Race_label Emotion_word  Emotion POMS_label  \n",
      "ID_F  ID_CF                                                                \n",
      "1     17825  African-American          1      enraged    anger          1  \n",
      "3     21347  African-American          1         pity  sadness          4  \n",
      "5     32741  African-American          1   uneasiness     fear          2  \n",
      "11    4939   African-American          1    depressed  sadness          4  \n",
      "12    34412  African-American          1      shocked     fear          2  \n",
      "...                       ...        ...          ...      ...        ...  \n",
      "69560 66632          European          0          NaN      NaN          0  \n",
      "69561 67101          European          0          NaN      NaN          0  \n",
      "69579 68299               NaN          0          NaN      NaN          0  \n",
      "69584 68084               NaN          0          NaN      NaN          0  \n",
      "69586 66202               NaN          0          NaN      NaN          0  \n",
      "\n",
      "[19603 rows x 12 columns]\n",
      "Number of sequences in dataset: 19603\n",
      "Max sequence length in dataset: 26\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 12.187369280212213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:41 - create_biased_datasets took 0.55 seconds to complete\n",
      "21:18:41 - Started create_biased_datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Person_F     Person_CF  \\\n",
      "ID_F  ID_CF                          \n",
      "1     17825   Alonzo       Tanisha   \n",
      "3     21347   Alonzo      Nichelle   \n",
      "5     32741   Alonzo       Lakisha   \n",
      "11    4939    Alonzo        Latoya   \n",
      "12    34412   Alonzo         Ebony   \n",
      "...              ...           ...   \n",
      "69595 66931  my aunt        my dad   \n",
      "69596 68992   my mom    my brother   \n",
      "69597 65745   my mom    my brother   \n",
      "69598 66898   my mom      this man   \n",
      "69599 68775   my mom  my boyfriend   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  Alonzo feels enraged as he paces along to the ...   \n",
      "3     21347   Alonzo feels pity as he paces along to the shop.   \n",
      "5     32741  Alonzo feels uneasiness as he paces along to t...   \n",
      "11    4939   The situation makes Alonzo feel depressed, but...   \n",
      "12    34412  Even though it is still a work in progress, th...   \n",
      "...                                                        ...   \n",
      "69595 66931                           My aunt has two cousins.   \n",
      "69596 68992  I bumped into my mom in the restaurant yesterday.   \n",
      "69597 65745                      I talked to my mom yesterday.   \n",
      "69598 66898     My mom goes to the school in our neighborhood.   \n",
      "69599 68775                            My mom has two cousins.   \n",
      "\n",
      "                                                   Sentence_CF Gender_F_label  \\\n",
      "ID_F  ID_CF                                                                     \n",
      "1     17825  Tanisha feels enraged as she paces along to th...              0   \n",
      "3     21347  Nichelle feels pity as she paces along to the ...              0   \n",
      "5     32741  Lakisha feels uneasiness as she paces along to...              0   \n",
      "11    4939   The situation makes Latoya feel depressed, but...              0   \n",
      "12    34412  Even though it is still a work in progress, th...              0   \n",
      "...                                                        ...            ...   \n",
      "69595 66931                           My dad has five cousins.              1   \n",
      "69596 68992  I saw my brother in the market every day durin...              1   \n",
      "69597 65745                  I talked to my brother yesterday.              1   \n",
      "69598 66898   This man goes to the school in our neighborhood.              1   \n",
      "69599 68775                      My boyfriend has no siblings.              1   \n",
      "\n",
      "            Gender_CF_label  \\\n",
      "ID_F  ID_CF                   \n",
      "1     17825               1   \n",
      "3     21347               1   \n",
      "5     32741               1   \n",
      "11    4939                1   \n",
      "12    34412               1   \n",
      "...                     ...   \n",
      "69595 66931               0   \n",
      "69596 68992               0   \n",
      "69597 65745               0   \n",
      "69598 66898               0   \n",
      "69599 68775               0   \n",
      "\n",
      "                                                      Template  \\\n",
      "ID_F  ID_CF                                                      \n",
      "1     17825  <person> feels enraged as <gender_noun> paces ...   \n",
      "3     21347  <person> feels pity as <gender_noun> paces alo...   \n",
      "5     32741  <person> feels uneasiness as <gender_noun> pac...   \n",
      "11    4939   The situation makes <person> feel depressed, b...   \n",
      "12    34412  Even though it is still a work in progress, th...   \n",
      "...                                                        ...   \n",
      "69595 66931                    <person> has <number> <family>.   \n",
      "69596 68992         I <observe> <person> in the <place> <day>.   \n",
      "69597 65745                        I talked to <person> <day>.   \n",
      "69598 66898   <person> goes to the school in our neighborhood.   \n",
      "69599 68775                    <person> has <number> <family>.   \n",
      "\n",
      "                         Race Race_label Emotion_word  Emotion POMS_label  \n",
      "ID_F  ID_CF                                                                \n",
      "1     17825  African-American          1      enraged    anger          1  \n",
      "3     21347  African-American          1         pity  sadness          4  \n",
      "5     32741  African-American          1   uneasiness     fear          2  \n",
      "11    4939   African-American          1    depressed  sadness          4  \n",
      "12    34412  African-American          1      shocked     fear          2  \n",
      "...                       ...        ...          ...      ...        ...  \n",
      "69595 66931               NaN          0          NaN      NaN          0  \n",
      "69596 68992               NaN          0          NaN      NaN          0  \n",
      "69597 65745               NaN          0          NaN      NaN          0  \n",
      "69598 66898               NaN          0          NaN      NaN          0  \n",
      "69599 68775               NaN          0          NaN      NaN          0  \n",
      "\n",
      "[32217 rows x 12 columns]\n",
      "Number of sequences in dataset: 32217\n",
      "Max sequence length in dataset: 26\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 12.10360989539684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:42 - create_biased_datasets took 0.89 seconds to complete\n",
      "21:18:42 - Started create_poms_dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Race enriched_noisy datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:19:12 - create_poms_dataset took 29.87 seconds to complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Person_F Person_CF  \\\n",
      "ID_F  ID_CF                        \n",
      "3     15235     Alonzo      Josh   \n",
      "4     26308     Alonzo      Adam   \n",
      "11    26475     Alonzo     Frank   \n",
      "14    9742      Alonzo      Alan   \n",
      "17    15249     Alonzo      Josh   \n",
      "...                ...       ...   \n",
      "69559 65795  Stephanie   Jasmine   \n",
      "69560 68824      Ellen    Latoya   \n",
      "69561 66957      Ellen   Tanisha   \n",
      "69562 65330      Ellen   Jasmine   \n",
      "69563 67655      Ellen   Tanisha   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "3     15235   Alonzo feels pity as he paces along to the shop.   \n",
      "4     26308  As he approaches the university, Alonzo feels ...   \n",
      "11    26475  The situation makes Alonzo feel depressed, but...   \n",
      "14    9742   Even though it is still a work in progress, th...   \n",
      "17    15249  I made Alonzo feel mad, and plan to continue u...   \n",
      "...                                                        ...   \n",
      "69559 65795                           Stephanie has five kids.   \n",
      "69560 68824                I saw Ellen in the shop last night.   \n",
      "69561 66957                    I talked to Ellen two days ago.   \n",
      "69562 65330      Ellen goes to the school in our neighborhood.   \n",
      "69563 67655                            Ellen has four cousins.   \n",
      "\n",
      "                                                   Sentence_CF  Race_F_label  \\\n",
      "ID_F  ID_CF                                                                    \n",
      "3     15235     Josh feels pity as he paces along to the shop.             1   \n",
      "4     26308  As he approaches the school, Adam feels scared...             1   \n",
      "11    26475  The situation makes Frank feel depressed, but ...             1   \n",
      "14    9742   Even though it is still a work in progress, th...             1   \n",
      "17    15249  I made Josh feel mad, and plan to continue unt...             1   \n",
      "...                                                        ...           ...   \n",
      "69559 65795                         Jasmine has five siblings.             0   \n",
      "69560 68824  I noticed Latoya in the school every day durin...             0   \n",
      "69561 66957                     I talked to Tanisha yesterday.             0   \n",
      "69562 65330    Jasmine goes to the school in our neighborhood.             0   \n",
      "69563 67655                            Tanisha has three kids.             0   \n",
      "\n",
      "             Race_CF_label                                           Template  \\\n",
      "ID_F  ID_CF                                                                     \n",
      "3     15235              0  <person> feels pity as <gender_noun> paces alo...   \n",
      "4     26308              0  As <gender_noun> approaches the <place>, <pers...   \n",
      "11    26475              0  The situation makes <person> feel depressed, b...   \n",
      "14    9742               0  Even though it is still a work in progress, th...   \n",
      "17    15249              0  I made <person> feel mad, and plan to continue...   \n",
      "...                    ...                                                ...   \n",
      "69559 65795              1                    <person> has <number> <family>.   \n",
      "69560 68824              1         I <observe> <person> in the <place> <day>.   \n",
      "69561 66957              1                        I talked to <person> <day>.   \n",
      "69562 65330              1   <person> goes to the school in our neighborhood.   \n",
      "69563 67655              1                    <person> has <number> <family>.   \n",
      "\n",
      "             Gender  Gender_label Emotion_word  Emotion  POMS_label  \n",
      "ID_F  ID_CF                                                          \n",
      "3     15235    male             0         pity  sadness           4  \n",
      "4     26308    male             0       scared     fear           2  \n",
      "11    26475    male             0    depressed  sadness           4  \n",
      "14    9742     male             0    wonderful      joy           3  \n",
      "17    15249    male             0          mad    anger           1  \n",
      "...             ...           ...          ...      ...         ...  \n",
      "69559 65795  female             1          NaN      NaN           0  \n",
      "69560 68824  female             1          NaN      NaN           0  \n",
      "69561 66957  female             1          NaN      NaN           0  \n",
      "69562 65330  female             1          NaN      NaN           0  \n",
      "69563 67655  female             1          NaN      NaN           0  \n",
      "\n",
      "[24901 rows x 12 columns]\n",
      "Number of sequences in dataset: 24901\n",
      "Max sequence length in dataset: 25\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 11.893056503754869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:19:13 - Started create_biased_datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biasing Race enriched_noisy dataset\n",
      "              Person_F Person_CF  \\\n",
      "ID_F  ID_CF                        \n",
      "14    9742      Alonzo      Alan   \n",
      "22    24758     Alonzo      Jack   \n",
      "30    22814     Alonzo    Justin   \n",
      "47    20879      Jamel      Alan   \n",
      "62    20894      Jamel      Alan   \n",
      "...                ...       ...   \n",
      "69559 65795  Stephanie   Jasmine   \n",
      "69560 68824      Ellen    Latoya   \n",
      "69561 66957      Ellen   Tanisha   \n",
      "69562 65330      Ellen   Jasmine   \n",
      "69563 67655      Ellen   Tanisha   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "14    9742   Even though it is still a work in progress, th...   \n",
      "22    24758  I have no idea how or why, but i made Alonzo f...   \n",
      "30    22814  It was totally unexpected, but Alonzo made me ...   \n",
      "47    20879  The situation makes Jamel feel relieved, and w...   \n",
      "62    20894  It was totally unexpected, but Jamel made me f...   \n",
      "...                                                        ...   \n",
      "69559 65795                           Stephanie has five kids.   \n",
      "69560 68824                I saw Ellen in the shop last night.   \n",
      "69561 66957                    I talked to Ellen two days ago.   \n",
      "69562 65330      Ellen goes to the school in our neighborhood.   \n",
      "69563 67655                            Ellen has four cousins.   \n",
      "\n",
      "                                                   Sentence_CF Race_F_label  \\\n",
      "ID_F  ID_CF                                                                   \n",
      "14    9742   Even though it is still a work in progress, th...            1   \n",
      "22    24758  I have no idea how or why, but i made Jack fee...            1   \n",
      "30    22814  It was totally unexpected, but Justin made me ...            1   \n",
      "47    20879  The situation makes Alan feel relieved, and wi...            1   \n",
      "62    20894  It was totally unexpected, but Alan made me fe...            1   \n",
      "...                                                        ...          ...   \n",
      "69559 65795                         Jasmine has five siblings.            0   \n",
      "69560 68824  I noticed Latoya in the school every day durin...            0   \n",
      "69561 66957                     I talked to Tanisha yesterday.            0   \n",
      "69562 65330    Jasmine goes to the school in our neighborhood.            0   \n",
      "69563 67655                            Tanisha has three kids.            0   \n",
      "\n",
      "            Race_CF_label                                           Template  \\\n",
      "ID_F  ID_CF                                                                    \n",
      "14    9742              0  Even though it is still a work in progress, th...   \n",
      "22    24758             0  I have no idea how or why, but i made <person>...   \n",
      "30    22814             0  It was totally unexpected, but <person> made m...   \n",
      "47    20879             0  The situation makes <person> feel relieved, an...   \n",
      "62    20894             0  It was totally unexpected, but <person> made m...   \n",
      "...                   ...                                                ...   \n",
      "69559 65795             1                    <person> has <number> <family>.   \n",
      "69560 68824             1         I <observe> <person> in the <place> <day>.   \n",
      "69561 66957             1                        I talked to <person> <day>.   \n",
      "69562 65330             1   <person> goes to the school in our neighborhood.   \n",
      "69563 67655             1                    <person> has <number> <family>.   \n",
      "\n",
      "             Gender Gender_label Emotion_word Emotion POMS_label  \n",
      "ID_F  ID_CF                                                       \n",
      "14    9742     male            0    wonderful     joy          3  \n",
      "22    24758    male            0         glad     joy          3  \n",
      "30    22814    male            0       amazed     joy          3  \n",
      "47    20879    male            0     relieved     joy          3  \n",
      "62    20894    male            0     cheerful     joy          3  \n",
      "...             ...          ...          ...     ...        ...  \n",
      "69559 65795  female            1          NaN     NaN          0  \n",
      "69560 68824  female            1          NaN     NaN          0  \n",
      "69561 66957  female            1          NaN     NaN          0  \n",
      "69562 65330  female            1          NaN     NaN          0  \n",
      "69563 67655  female            1          NaN     NaN          0  \n",
      "\n",
      "[13686 rows x 12 columns]\n",
      "Number of sequences in dataset: 13686\n",
      "Max sequence length in dataset: 25\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 11.91750694139997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:19:13 - create_biased_datasets took 0.47 seconds to complete\n",
      "21:19:13 - Started create_biased_datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Person_F Person_CF  \\\n",
      "ID_F  ID_CF                        \n",
      "3     15235     Alonzo      Josh   \n",
      "4     26308     Alonzo      Adam   \n",
      "11    26475     Alonzo     Frank   \n",
      "14    9742      Alonzo      Alan   \n",
      "17    15249     Alonzo      Josh   \n",
      "...                ...       ...   \n",
      "69559 65795  Stephanie   Jasmine   \n",
      "69560 68824      Ellen    Latoya   \n",
      "69561 66957      Ellen   Tanisha   \n",
      "69562 65330      Ellen   Jasmine   \n",
      "69563 67655      Ellen   Tanisha   \n",
      "\n",
      "                                                    Sentence_F  \\\n",
      "ID_F  ID_CF                                                      \n",
      "3     15235   Alonzo feels pity as he paces along to the shop.   \n",
      "4     26308  As he approaches the university, Alonzo feels ...   \n",
      "11    26475  The situation makes Alonzo feel depressed, but...   \n",
      "14    9742   Even though it is still a work in progress, th...   \n",
      "17    15249  I made Alonzo feel mad, and plan to continue u...   \n",
      "...                                                        ...   \n",
      "69559 65795                           Stephanie has five kids.   \n",
      "69560 68824                I saw Ellen in the shop last night.   \n",
      "69561 66957                    I talked to Ellen two days ago.   \n",
      "69562 65330      Ellen goes to the school in our neighborhood.   \n",
      "69563 67655                            Ellen has four cousins.   \n",
      "\n",
      "                                                   Sentence_CF Race_F_label  \\\n",
      "ID_F  ID_CF                                                                   \n",
      "3     15235     Josh feels pity as he paces along to the shop.            1   \n",
      "4     26308  As he approaches the school, Adam feels scared...            1   \n",
      "11    26475  The situation makes Frank feel depressed, but ...            1   \n",
      "14    9742   Even though it is still a work in progress, th...            1   \n",
      "17    15249  I made Josh feel mad, and plan to continue unt...            1   \n",
      "...                                                        ...          ...   \n",
      "69559 65795                         Jasmine has five siblings.            0   \n",
      "69560 68824  I noticed Latoya in the school every day durin...            0   \n",
      "69561 66957                     I talked to Tanisha yesterday.            0   \n",
      "69562 65330    Jasmine goes to the school in our neighborhood.            0   \n",
      "69563 67655                            Tanisha has three kids.            0   \n",
      "\n",
      "            Race_CF_label                                           Template  \\\n",
      "ID_F  ID_CF                                                                    \n",
      "3     15235             0  <person> feels pity as <gender_noun> paces alo...   \n",
      "4     26308             0  As <gender_noun> approaches the <place>, <pers...   \n",
      "11    26475             0  The situation makes <person> feel depressed, b...   \n",
      "14    9742              0  Even though it is still a work in progress, th...   \n",
      "17    15249             0  I made <person> feel mad, and plan to continue...   \n",
      "...                   ...                                                ...   \n",
      "69559 65795             1                    <person> has <number> <family>.   \n",
      "69560 68824             1         I <observe> <person> in the <place> <day>.   \n",
      "69561 66957             1                        I talked to <person> <day>.   \n",
      "69562 65330             1   <person> goes to the school in our neighborhood.   \n",
      "69563 67655             1                    <person> has <number> <family>.   \n",
      "\n",
      "             Gender Gender_label Emotion_word  Emotion POMS_label  \n",
      "ID_F  ID_CF                                                        \n",
      "3     15235    male            0         pity  sadness          4  \n",
      "4     26308    male            0       scared     fear          2  \n",
      "11    26475    male            0    depressed  sadness          4  \n",
      "14    9742     male            0    wonderful      joy          3  \n",
      "17    15249    male            0          mad    anger          1  \n",
      "...             ...          ...          ...      ...        ...  \n",
      "69559 65795  female            1          NaN      NaN          0  \n",
      "69560 68824  female            1          NaN      NaN          0  \n",
      "69561 66957  female            1          NaN      NaN          0  \n",
      "69562 65330  female            1          NaN      NaN          0  \n",
      "69563 67655  female            1          NaN      NaN          0  \n",
      "\n",
      "[22345 rows x 12 columns]\n",
      "Number of sequences in dataset: 22345\n",
      "Max sequence length in dataset: 25\n",
      "Min sequence length in dataset: 4\n",
      "Median sequence length in dataset: 12.0\n",
      "Mean sequence length in dataset: 11.82689639740434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:19:14 - create_biased_datasets took 0.59 seconds to complete\n",
      "21:19:14 - create_all_datasets took 1 minutes and 11.96 seconds to complete\n",
      "21:19:14 - main took 1 minutes and 11.97 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "%run -i /home/nadavo/dev/CausaLM/datasets/POMS-GendeRace/create_poms_datasets.py --corpus_type enriched_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Pretraining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:35:46 - Started main\n",
      "69600it [00:00, 865145.82it/s]\n",
      "Document: 100%|| 69600/69600 [00:04<00:00, 14091.68it/s]\n",
      "Document: 100%|| 69600/69600 [00:04<00:00, 14402.59it/s]\n",
      "Document: 100%|| 69600/69600 [00:04<00:00, 14546.55it/s]\n",
      "Document: 100%|| 69600/69600 [00:04<00:00, 14227.49it/s]\n",
      "Document: 100%|| 69600/69600 [00:04<00:00, 14840.94it/s]\n",
      "21:36:06 - main took 20.34 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "%run -i /home/nadavo/dev/CausaLM/BERT/GendeRace/pregenerate_training_data.py --treatment gender --corpus_type enriched_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:36:06 - Started main\n",
      "48000it [00:00, 986493.69it/s]\n",
      "Document: 100%|| 48000/48000 [00:03<00:00, 13706.60it/s]\n",
      "Document: 100%|| 48000/48000 [00:03<00:00, 12769.12it/s]\n",
      "Document: 100%|| 48000/48000 [00:03<00:00, 12719.22it/s]\n",
      "Document: 100%|| 48000/48000 [00:03<00:00, 12812.52it/s]\n",
      "Document: 100%|| 48000/48000 [00:03<00:00, 13360.60it/s]\n",
      "21:36:22 - main took 16.06 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "%run -i /home/nadavo/dev/CausaLM/BERT/GendeRace/pregenerate_training_data.py --treatment race --corpus_type enriched_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
