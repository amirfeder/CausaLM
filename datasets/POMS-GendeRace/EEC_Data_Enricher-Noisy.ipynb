{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets.datasets_utils import split_data, print_text_stats\n",
    "from tqdm.contrib.itertools import product\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched_noisy.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<season>', season)\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<season>', season)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32480\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "                                  \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = ['no', 'one', 'two', 'three', 'four', 'five']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        place = random.choice(places)\n",
    "                        fam = random.choice(family)\n",
    "                        obs = random.choice(observe)\n",
    "                        num = random.choice(numbers)\n",
    "                        day = random.choice(days)\n",
    "                        \n",
    "                        cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        template = base_sentence\n",
    "#                         template = base_sentence.replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, template, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Noise Additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Correlated Noise Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sentences = [\"This is random noise\",\n",
    "                   \"This is only here to confuse the classifier\",\n",
    "                   \"No added information is given in this part\",\n",
    "                   \"Do not look here, it will just confuse you\",\n",
    "                   \"Sometimes noise helps, not here\",\n",
    "                   \"Really, there is no information here\",\n",
    "                   \"Nothing here is relevant\",\n",
    "                   \"This sentence is just a placeholder\",\n",
    "                   \"Why are you looking here\",\n",
    "                   \"When in doubt, use these words\",\n",
    "                   \"I'm just here so I won't get fined\",\n",
    "                   \"Yet another redundant sentence\",\n",
    "                   \"Look away, no information will be given here\",\n",
    "                  ]\n",
    "\n",
    "pdf_noisy_sentences_dict = {\n",
    "    \"anger\": [0.20]*3+[0.04]*10,\n",
    "    \"fear\": [0.04]*3+[0.20]*3+[0.04]*7,\n",
    "    \"joy\": [0.04]*6+[0.20]*3+[0.04]*4,\n",
    "    \"sadness\": [0.04]*9+[0.20]*3+[0.04]*1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_file, header=0, encoding=\"utf-8\")\n",
    "for row in df.itertuples():\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if random.random() > 0.5: # Add noisy sentence w.p 0.5\n",
    "        noise_sentence_id = np.random.choice(13, 1, p=pdf_noisy_sentences_dict[label])[0] # Choose sentence according to pdf\n",
    "        noise_sentence = noise_sentences[noise_sentence_id].lower()\n",
    "        if random.random() > 0.5: # Choose whether prefix or suffix\n",
    "            new_sentence = f\"{str(row.Sentence).replace('.', ',')} {noise_sentence}.\"\n",
    "            new_template = f\"{str(row.Template).replace('.', ',')} {noise_sentence}.\"\n",
    "        else:\n",
    "            new_sentence = f\"{noise_sentence}, {str(row.Sentence)}\"\n",
    "            new_template = f\"{noise_sentence}, {str(row.Template)}\"\n",
    "        df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "        df.at[row.Index, \"Template\"] = new_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Ambiguous Emotion Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Emotion Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict = {\n",
    "    \"joy\": [\n",
    "        \"blissful\", \"joyous\", \"delighted\", \"overjoyed\", \"gleeful\", \"thankful\", \"festive\", \"ecstatic\", \"satisfied\", \"cheerful\",\n",
    "        \"sunny\", \"elated\", \"jubilant\", \"jovial\", \"lighthearted\", \"glorious\", \"innocent\", \"gratified\", \"euphoric\", \"world\", \n",
    "        \"playful\", \"courageous\", \"energetic\", \"liberated\", \"optimistic\", \"frisky\", \"animated\", \"spirited\", \"thrilled\",\n",
    "        \"intelligent\", \"exhilarated\", \"spunky\", \"youthful\", \"vigorous\", \"tickled\", \"creative\", \n",
    "        \"constructive\", \"helpful\", \"resourceful\", \"comfortable\", \"pleased\", \"encouraged\", \"surprised\", \"content\", \n",
    "        \"serene\", \"bright\", \"blessed\", \"Vibrant\", \"Bountiful\", \"Glowing\"\n",
    "    ],\n",
    "    \"anger\": [\n",
    "        \"Ordeal\", \"Outrageousness\", \"Provoke\", \"Repulsive\", \"Scandal\", \"Severe\", \"Shameful\", \"Shocking\", \"Terrible\", \"Tragic\",\n",
    "        \"Unreliable\", \"Unstable\", \"Wicked\", \"Aggravate\", \"Agony\", \"Appalled\", \"Atrocious\", \"Corrupting\", \"Damaging\",\n",
    "        \"Deplorable\", \"Disadvantages\", \"Disastrous\", \"Disgusted\", \"Dreadful\", \"Eliminate\", \"Harmful\", \"Harsh\", \"Inconsiderate\",\n",
    "        \"enraged\", \"offensive\", \"aggressive\", \"frustrated\", \"controlling\", \"resentful\", \"malicious\", \"infuriated\", \"critical\",\n",
    "        \"violent\", \"vindictive\", \"sadistic\", \"spiteful\", \"furious\", \"agitated\", \"antagonistic\", \"repulsed\", \"quarrelsome\", \n",
    "        \"venomous\", \"rebellious\", \"exasperated\", \"impatient\", \"contrary\", \"condemning\", \"seething\", \"scornful\", \"sarcastic\",\n",
    "        \"poisonous\", \"jealous\", \"revengeful\", \"retaliating\", \"reprimanding\", \"powerless\", \"despicable\", \"desperate\", \"alienated\", \n",
    "        \"pessimistic\", \"dejected\", \"vilified\", \"unjustified\", \"violated\"\n",
    "    ],\n",
    "    \"sadness\": [\n",
    "        \"bitter\", \"dismal\", \"heartbroken\", \"melancholy\", \"mournful\", \"pessimistic\", \"somber\", \"sorrowful\", \"sorry\", \"wistful\",\n",
    "        \"bereaved\", \"blue\", \"cheerless\", \"dejected\", \"despairing\", \"despondent\", \"disconsolate\", \"distressed\", \"doleful\", \n",
    "        \"down\", \"downcast\", \"forlorn\", \"glum\", \"grieved\", \"heartsick\", \"heavyhearted\", \"hurting\", \"languishing\", \n",
    "        \"low\", \"lugubrious\", \"morbid\", \"morose\", \"pensive\", \"troubled\", \"weeping\", \"woebegone\",\n",
    "    ],\n",
    "    \"fear\": [\n",
    "        \"angst\", \"anxiety\", \"concern\", \"despair\", \"dismay\", \"doubt\", \"dread\", \"horror\", \"jitters\", \"panic\", \"scare\", \n",
    "        \"suspicion\", \"terror\", \"unease\", \"uneasiness\", \"worry\", \"abhorrence\", \"agitation\", \"aversion\", \"awe\", \"consternation\",\n",
    "        \"cowardice\", \"creeps\", \"discomposure\", \"disquietude\", \"distress\", \"faintheartedness\", \"foreboding\", \"fright\", \"funk\",\n",
    "        \"misgiving\", \"nightmare\", \"phobia\", \"presentiment\", \"qualm\", \"reverence\", \"revulsion\", \"timidity\", \"trembling\",\n",
    "        \"tremor\", \"trepidation\", \"chickenheartedness\", \"recreancy\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict2 = {\n",
    "    \"anger\": [\"rage\", \"ire\", \"indignation\", \"resentment\", \"wrath\", \"annoyance\", \"outrage\", \"exasperate\",\n",
    "              \"choler\", \"hatred\", \"aggression\", \"fury\", \"emotions\", \"provoke\", \"hostility\", \"frustration\",\n",
    "              \"displeasure\", \"exasperation\", \"dissatisfaction\", \"anxiety\", \"disgust\",\n",
    "              \"animosity\", \"adrenaline\", \"enrage\", \"madden\", \"infuriate\", \"umbrage\", \"exacerbate\", \"angry\",\n",
    "              \"gall\", \"chafe\", \"miff\", \"violence\", \"ira\", \"pique\", \"furious\", \"aggravate\", \"angriness\",\n",
    "              \"vexation\", \"spite\", \"irk\", \"offend\", \"madness\", \"stress\", \"infuriation\", \"embarrassment\",\n",
    "              \"dismay\", \"discontent\", \"bitterness\", \"unease\", \"despair\", \"distrust\",\n",
    "              \"skepticism\", \"criticism\", \"backlash\", \"outcry\", \"grief\", \"tensions\", \"revulsion\",\n",
    "              \"disappointment\", \"anguish\", \"consternation\", \"sorrow\",\n",
    "              \"cynicism\", \"unhappiness\", \"disdain\", \"uproar\", \"irritation\", \"jealousy\", \"impatience\",\n",
    "              \"angst\", \"uneasiness\", \"disquiet\"],\n",
    "    \"sadness\": [\"sorry\", \"melancholy\", \"tragic\", \"lamentable\", \"pitiful\", \"mournful\", \"deplorable\",\n",
    "                \"bad\", \"bittersweet\", \"sorrowful\", \"miserable\", \"doleful\", \"melancholic\",\n",
    "                \"pensive\", \"distressing\", \"wistful\", \"unhappy\", \"pathetic\", \"sadly\", \"sadness\",\n",
    "                \"regret\", \"tragical\",\"pity\", \"heavyhearted\", \"tragicomic\", \"tragicomical\",\n",
    "                \"cry\", \"awful\", \"terrible\", \"depressive\", \"sorrow\", \"horrible\", \"sadden\", \"weird\",\n",
    "                \"scary\", \"unfortunate\", \"shocking\", \"regrettable\", \"regretful\", \"heartbreaking\",\n",
    "                \"frightening\", \"ashamed\", \"hopeless\", \"ironic\", \"despondent\",\n",
    "                \"sombre\", \"somber\", \"gloomy\", \"saddening\", \"depressing\",\n",
    "                \"despair\", \"brokenhearted\", \"crying\", \"woebegone\", \"anger\", \"surprise\",\n",
    "                \"mourn\", \"disgust\", \"suffering\", \"mourner\", \"dejection\", \"bewail\",\n",
    "                \"contrite\", \"mania\", \"deplore\", \"terribly\", \"lament\", \"alas\", \"grieve\",\n",
    "                \"hardly\", \"moment\"],\n",
    "    \"fear\": [\"panic\", \"anxiety\", \"dread\", \"phobia\", \"risk\", \"fright\", \"fearfulness\", \"concern\",\n",
    "             \"acrophobia\", \"awe\", \"horror\", \"afraid\", \"intimidation\", \"apprehension\", \"worry\",\n",
    "             \"danger\", \"angst\", \"reverence\", \"claustrophobia\", \"amygdala\", \"veneration\",\n",
    "             \"scare\", \"affright\", \"unafraid\", \"timidity\", \"terror\", \"consternation\", \"dismay\", \n",
    "             \"fearless\", \"hysteria\", \"alarm\", \"threat\", \"fearful\", \"cold sweat\", \"frisson\", \n",
    "             \"arachnophobia\", \"venerate\", \"care\", \"revere\", \"failure\"],\n",
    "    \"joy\": [\"gladden\", \"happiness\", \"delight\", \"pleasure\", \"rejoice\", \"excitement\", \"exultation\",\n",
    "            \"elation\", \"exuberance\", \"cheer\", \"exhilaration\", \"joyousness\", \"joyfulness\", \"pride\",\n",
    "            \"gratitude\", \"overjoy\", \"exult\", \"joyful\", \"happy\", \"ecstatic\", \"cheer up\", \"jubilation\",\n",
    "            \"gladness\", \"jubilance\", \"smile\", \"contentment\", \"passion\", \"sorrow\", \"grief\",\n",
    "            \"tears\", \"love\", \"blessedness\", \"bliss\", \"anguish\", \"laughter\", \"satisfaction\", \"admiration\",\n",
    "            \"awe\", \"gratification\", \"despair\", \"spirit\", \"longing\", \"luck\", \"agony\", \"euphoria\", \n",
    "            \"enthusiasm\", \"warmth\", \"heartache\", \"thank\", \"goodness\", \"frustration\", \"amazement\", \n",
    "            \"glee\", \"enjoyment\", \"mirth\", \"contentedness\", \"joyance\", \"rhapsody\", \"experience\", \n",
    "            \"lightness\", \"blissful\", \"joyous\", \"cheerfulness\", \"glad\", \"exultant\", \"jubilancy\", \"happily\", \n",
    "            \"winne\", \"fain\", \"felicity\", \"elate\", \"complacence\", \"affection\", \"kindness\", \"felicitous\", \n",
    "            \"grace\", \"pity\", \"gaiety\", \"hedonism\", \"feeling\", \"cry\", \"wonderful\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy anger\n",
      "{'sorrow', 'despair', 'anguish', 'frustration', 'grief'}\n",
      "joy sadness\n",
      "{'sorrow', 'despair', 'cry', 'pity'}\n",
      "joy fear\n",
      "{'despair', 'awe'}\n",
      "anger sadness\n",
      "{'sorrow', 'despair', 'pessimistic', 'disgust', 'dejected'}\n",
      "anger fear\n",
      "{'unease', 'despair', 'angst', 'anxiety', 'dismay', 'consternation', 'uneasiness', 'revulsion'}\n",
      "sadness fear\n",
      "{'despair'}\n",
      "joy {'sorrow', 'despair', 'anguish', 'awe', 'frustration', 'grief', 'cry', 'pity'} 8\n",
      "anger {'sorrow', 'despair', 'unease', 'anguish', 'angst', 'anxiety', 'pessimistic', 'frustration', 'disgust', 'dismay', 'grief', 'consternation', 'uneasiness', 'revulsion', 'dejected'} 15\n",
      "sadness {'sorrow', 'despair', 'pessimistic', 'disgust', 'cry', 'pity', 'dejected'} 7\n",
      "fear {'despair', 'unease', 'awe', 'angst', 'anxiety', 'dismay', 'consternation', 'uneasiness', 'revulsion'} 9\n",
      "nan {''} 1\n"
     ]
    }
   ],
   "source": [
    "add_emotion_words_dict = {key: set(additional_emotion_words_dict[key]) | set(additional_emotion_words_dict2[key]) for key in additional_emotion_words_dict.keys()}\n",
    "ambg_emotion_words_dict = defaultdict(set)\n",
    "\n",
    "for i, j in combinations(add_emotion_words_dict.keys(), 2):\n",
    "    cur_intersction = add_emotion_words_dict[i].intersection(add_emotion_words_dict[j])\n",
    "    if cur_intersction:\n",
    "        print(i, j)\n",
    "        print(cur_intersction)\n",
    "        ambg_emotion_words_dict[i] |= cur_intersction\n",
    "        ambg_emotion_words_dict[j] |= cur_intersction\n",
    "\n",
    "add_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "ambg_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "for key, val in ambg_emotion_words_dict.items():\n",
    "    print(key, val, len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly replace emotion words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                           Sentence  \\\n",
      "11631  11631  The situation makes Frank feel love, and will ...   \n",
      "2959    2959  The situation makes Jasmine feel pity, and wil...   \n",
      "20279  20279  Roger told us all about the recent wonderful e...   \n",
      "28821  28821  This boy told us all about the recent funk eve...   \n",
      "25428  25428  To our surprise, my girlfriend found herself i...   \n",
      "\n",
      "                                                Template         Person  \\\n",
      "11631  The situation makes <person> feel love, and wi...          Frank   \n",
      "2959   The situation makes <person> feel pity, and wi...        Jasmine   \n",
      "20279  <person> told us all about the recent pity eve...          Roger   \n",
      "28821  <person> told us all about the recent funk eve...       this boy   \n",
      "25428  To our surprise, <person> found <gender_noun> ...  my girlfriend   \n",
      "\n",
      "       Gender              Race Emotion Emotion_word new_Emotion_word  \n",
      "11631    male          European     joy      excited             love  \n",
      "2959   female  African-American     joy        funny             pity  \n",
      "20279    male          European     joy    wonderful        wonderful  \n",
      "28821    male               NaN    fear     horrible             funk  \n",
      "25428  female               NaN    fear  threatening            angst  \n"
     ]
    }
   ],
   "source": [
    "# random_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "# ambiguous_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "\n",
    "# def replace_emotion_word(df, words_dict):\n",
    "#     df[\"new_Emotion_word\"] = df[\"Emotion\"].apply(lambda emotion: str(choice(words_dict[str(emotion)])).lower())\n",
    "#     df[\"Sentence\"] = df.apply(lambda row: str(row[\"Sentence\"]).replace(str(row[\"Emotion_word\"]), str(row[\"new_Emotion_word\"])), axis=1)\n",
    "\n",
    "# # Replace with new random emotion word\n",
    "# replace_emotion_word(random_replace_df, add_emotion_words_dict)\n",
    "\n",
    "# # Replace with new random ambiguous emotion word\n",
    "# replace_emotion_word(ambiguous_replace_df, ambg_emotion_words_dict)\n",
    "\n",
    "shuffled_df = df.sample(frac=1).copy()\n",
    "shuffled_df[\"new_Emotion_word\"] = shuffled_df[\"Emotion_word\"]\n",
    "for i, row in enumerate(shuffled_df.itertuples()):\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if i % 3 == 0:\n",
    "        new_emotion_word = str(random.sample(add_emotion_words_dict[label], 1)[0]).lower()\n",
    "    elif i % 3 == 1:\n",
    "        new_emotion_word = str(random.sample(ambg_emotion_words_dict[label], 1)[0]).lower()\n",
    "    else:\n",
    "        new_template = str(row.Template).replace(\"<emotion>\", new_emotion_word)\n",
    "        shuffled_df.at[row.Index, \"Template\"] = new_template\n",
    "        continue\n",
    "    new_sentence = str(row.Sentence).replace(str(row.Emotion_word), new_emotion_word)\n",
    "    new_template = str(row.Template).replace(\"<emotion>\", new_emotion_word)\n",
    "    shuffled_df.at[row.Index, \"new_Emotion_word\"] = new_emotion_word\n",
    "    shuffled_df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "    shuffled_df.at[row.Index, \"Template\"] = new_template\n",
    "\n",
    "print(shuffled_df.head())\n",
    "shuffled_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word', 'new_Emotion_word'],\n",
      "      dtype='object')\n",
      "sadness    8120\n",
      "joy        8120\n",
      "anger      8120\n",
      "fear       8120\n",
      "NaN        2320\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      17400\n",
      "female    17400\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "European            12000\n",
      "African-American    12000\n",
      "NaN                 10800\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "Adam             600\n",
      "this man         600\n",
      "my dad           600\n",
      "my mother        600\n",
      "Tia              600\n",
      "Stephanie        600\n",
      "my uncle         600\n",
      "Terrence         600\n",
      "my sister        600\n",
      "Alphonse         600\n",
      "Justin           600\n",
      "Kristin          600\n",
      "my brother       600\n",
      "Latisha          600\n",
      "this girl        600\n",
      "Jamel            600\n",
      "Alonzo           600\n",
      "Lamar            600\n",
      "Ellen            600\n",
      "Andrew           600\n",
      "Betsy            600\n",
      "Jerome           600\n",
      "Tanisha          600\n",
      "Roger            600\n",
      "Nichelle         600\n",
      "Shereen          600\n",
      "Shaniqua         600\n",
      "my daughter      600\n",
      "Melanie          600\n",
      "Katie            600\n",
      "Alan             600\n",
      "my wife          600\n",
      "Jasmine          600\n",
      "Harry            600\n",
      "Latoya           600\n",
      "Leroy            600\n",
      "Heather          600\n",
      "Josh             600\n",
      "this boy         600\n",
      "Torrance         600\n",
      "Darnell          600\n",
      "Malik            600\n",
      "my father        600\n",
      "Ebony            600\n",
      "this woman       600\n",
      "Frank            600\n",
      "my son           600\n",
      "Nancy            600\n",
      "my aunt          600\n",
      "my mom           600\n",
      "my girlfriend    600\n",
      "Courtney         600\n",
      "Amanda           600\n",
      "Lakisha          600\n",
      "Ryan             600\n",
      "Jack             600\n",
      "my husband       600\n",
      "my boyfriend     600\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              2320\n",
      "funny            1199\n",
      "dreadful         1162\n",
      "wonderful        1136\n",
      "gloomy           1125\n",
      "horrible         1104\n",
      "great            1069\n",
      "hilarious         738\n",
      "displeasing       730\n",
      "grim              722\n",
      "terrifying        718\n",
      "threatening       713\n",
      "depressing        713\n",
      "vexing            706\n",
      "outrageous        696\n",
      "shocking          694\n",
      "heartbreaking     690\n",
      "irritating        687\n",
      "amazing           677\n",
      "serious           661\n",
      "annoying          661\n",
      "glad              507\n",
      "amazed            504\n",
      "relieved          503\n",
      "downhearted       499\n",
      "angry             496\n",
      "frightened        495\n",
      "discouraged       487\n",
      "anxious           486\n",
      "crushed           485\n",
      "sad               481\n",
      "disappointed      476\n",
      "annoyed           476\n",
      "infuriated        474\n",
      "cheerful          471\n",
      "vexed             471\n",
      "excited           470\n",
      "irate             470\n",
      "depressed         466\n",
      "devastated        465\n",
      "terrified         464\n",
      "mad               464\n",
      "threatened        458\n",
      "shocked           455\n",
      "fearful           455\n",
      "troubled          453\n",
      "unhappy           453\n",
      "irritated         452\n",
      "furious           450\n",
      "enraged           447\n",
      "outraged          440\n",
      "miserable         431\n",
      "scared            429\n",
      "ecstatic          429\n",
      "happy             417\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n",
      "NaN           2320\n",
      "despair       1283\n",
      "sorrow         973\n",
      "cry            769\n",
      "pity           764\n",
      "              ... \n",
      "delighted       11\n",
      "exacerbate      11\n",
      "violated        10\n",
      "euphoric        10\n",
      "skepticism       9\n",
      "Name: new_Emotion_word, Length: 441, dtype: int64 \n",
      "\n",
      "I <observe> <person> in the <place> <day>.                                                            580\n",
      "I talked to <person> <day>.                                                                           580\n",
      "<person> goes to the school in our neighborhood.                                                      580\n",
      "<person> has <number> <family>.                                                                       580\n",
      "The conversation with <person> was despair, we could from simply looking                               55\n",
      "                                                                                                     ... \n",
      "<person> feels saddening at the start                                                                   1\n",
      "The conversation with <person> was helpful, you could feel it in the air why are you looking here.      1\n",
      "this sentence is just a placeholder, As <gender_noun> approaches the <place>, <person> feels awe        1\n",
      "<person> feels cry as <gender_noun> walks to the <place> i'm just here so i won't get fined.            1\n",
      "why are you looking here, The conversation with <person> was sorrow, we could from simply looking       1\n",
      "Name: Template, Length: 17634, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(shuffled_df))\n",
    "print(shuffled_df.columns)\n",
    "for col in (\"Emotion\", \"Gender\", \"Race\", \"Person\", \"Emotion_word\", \"new_Emotion_word\", \"Template\"):\n",
    "    print(shuffled_df[col].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
