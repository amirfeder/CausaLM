{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets_utils import split_data, print_text_stats\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched_noisy.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        prefix_template = prefix_template.replace('<place>', place).replace('<season>', season)\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        suffix_template = suffix_template.replace('<place>', place).replace('<season>', season)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32480\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        prefix_template = prefix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "                                  \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        suffix_template = suffix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = ['no', 'one', 'two', 'three', 'four', 'five']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        place = random.choice(places)\n",
    "                        fam = random.choice(family)\n",
    "                        obs = random.choice(observe)\n",
    "                        num = random.choice(numbers)\n",
    "                        day = random.choice(days)\n",
    "                        \n",
    "                        cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        template = base_sentence.replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, template, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                           Sentence  \\\n",
      "0   0  As he approaches the market, Alonzo feels enra...   \n",
      "1   1  Alonzo feels angry as he paces along to the su...   \n",
      "2   2  As he approaches the market, Alonzo feels trou...   \n",
      "3   3  Alonzo feels crushed as he paces along to the ...   \n",
      "4   4  As he approaches the market, Alonzo feels fear...   \n",
      "\n",
      "                                            Template  Person Gender  \\\n",
      "0  As <gender_noun> approaches the market, <perso...  Alonzo   male   \n",
      "1  <person> feels <emotion> as <gender_noun> pace...  Alonzo   male   \n",
      "2  As <gender_noun> approaches the market, <perso...  Alonzo   male   \n",
      "3  <person> feels <emotion> as <gender_noun> pace...  Alonzo   male   \n",
      "4  As <gender_noun> approaches the market, <perso...  Alonzo   male   \n",
      "\n",
      "               Race  Emotion Emotion_word  \n",
      "0  African-American    anger      enraged  \n",
      "1  African-American    anger        angry  \n",
      "2  African-American  sadness     troubled  \n",
      "3  African-American  sadness      crushed  \n",
      "4  African-American     fear      fearful  \n",
      "          ID                                           Sentence  \\\n",
      "27238  27238  As we were walking together, Roger told us all...   \n",
      "1586    1586  It is far from over, but so far i made this wo...   \n",
      "22114  22114  To our surprise, Latisha found herself in a gr...   \n",
      "27543  27543  My father found himself in a wonderful situati...   \n",
      "23896  23896  As we were walking together, Ellen told us all...   \n",
      "\n",
      "                                                Template      Person  Gender  \\\n",
      "27238  As we were walking together, <person> told us ...       Roger    male   \n",
      "1586   It is far from over, but so far i made <person...  this woman  female   \n",
      "22114  To our surprise, <person> found <gender_noun> ...     Latisha  female   \n",
      "27543  <person> found <gender_noun> in <ind> <emotion...   my father    male   \n",
      "23896  As we were walking together, <person> told us ...       Ellen  female   \n",
      "\n",
      "                   Race  Emotion Emotion_word  \n",
      "27238          European      joy    wonderful  \n",
      "1586                NaN  sadness       gloomy  \n",
      "22114  African-American  sadness         grim  \n",
      "27543               NaN      joy    wonderful  \n",
      "23896          European    anger   irritating  \n"
     ]
    }
   ],
   "source": [
    "enriched_df = pd.read_csv(output_file, header=0)\n",
    "print(enriched_df.head())\n",
    "shuffled_enriched_df = enriched_df.sample(frac=1)\n",
    "print(shuffled_enriched_df.head())\n",
    "shuffled_enriched_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word'],\n",
      "      dtype='object')\n",
      "sadness    8120\n",
      "fear       8120\n",
      "anger      8120\n",
      "joy        8120\n",
      "NaN        2320\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      17400\n",
      "female    17400\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "European            12000\n",
      "African-American    12000\n",
      "NaN                 10800\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "my father        600\n",
      "Stephanie        600\n",
      "Alan             600\n",
      "Alphonse         600\n",
      "Amanda           600\n",
      "Alonzo           600\n",
      "my son           600\n",
      "Shereen          600\n",
      "this woman       600\n",
      "Darnell          600\n",
      "Ryan             600\n",
      "Frank            600\n",
      "this girl        600\n",
      "Leroy            600\n",
      "this man         600\n",
      "Harry            600\n",
      "my dad           600\n",
      "Latisha          600\n",
      "Jerome           600\n",
      "Justin           600\n",
      "Jasmine          600\n",
      "Malik            600\n",
      "my husband       600\n",
      "my mother        600\n",
      "my wife          600\n",
      "Katie            600\n",
      "Latoya           600\n",
      "Roger            600\n",
      "Ellen            600\n",
      "Terrence         600\n",
      "Nancy            600\n",
      "Andrew           600\n",
      "my boyfriend     600\n",
      "Nichelle         600\n",
      "Tia              600\n",
      "Melanie          600\n",
      "Lakisha          600\n",
      "my mom           600\n",
      "my sister        600\n",
      "Shaniqua         600\n",
      "Betsy            600\n",
      "my uncle         600\n",
      "Kristin          600\n",
      "my daughter      600\n",
      "this boy         600\n",
      "Tanisha          600\n",
      "my girlfriend    600\n",
      "my aunt          600\n",
      "Ebony            600\n",
      "Josh             600\n",
      "Heather          600\n",
      "my brother       600\n",
      "Torrance         600\n",
      "Courtney         600\n",
      "Adam             600\n",
      "Jack             600\n",
      "Jamel            600\n",
      "Lamar            600\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              2320\n",
      "gloomy           1180\n",
      "wonderful        1178\n",
      "great            1167\n",
      "horrible         1155\n",
      "dreadful         1145\n",
      "funny            1131\n",
      "threatening       754\n",
      "outrageous        747\n",
      "displeasing       714\n",
      "heartbreaking     706\n",
      "hilarious         701\n",
      "grim              700\n",
      "shocking          692\n",
      "vexing            687\n",
      "serious           682\n",
      "depressing        675\n",
      "terrifying        673\n",
      "irritating        670\n",
      "amazing           665\n",
      "annoying          662\n",
      "infuriated        526\n",
      "scared            501\n",
      "unhappy           494\n",
      "cheerful          492\n",
      "ecstatic          490\n",
      "glad              485\n",
      "crushed           484\n",
      "threatened        484\n",
      "disappointed      480\n",
      "outraged          479\n",
      "mad               478\n",
      "vexed             475\n",
      "annoyed           467\n",
      "amazed            466\n",
      "troubled          462\n",
      "miserable         462\n",
      "angry             461\n",
      "terrified         461\n",
      "fearful           460\n",
      "furious           458\n",
      "shocked           458\n",
      "irritated         456\n",
      "downhearted       454\n",
      "relieved          453\n",
      "devastated        450\n",
      "excited           450\n",
      "discouraged       448\n",
      "sad               446\n",
      "depressed         445\n",
      "anxious           445\n",
      "frightened        444\n",
      "happy             442\n",
      "enraged           434\n",
      "irate             406\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(enriched_df))\n",
    "print(enriched_df.columns)\n",
    "for col in (\"Emotion\", \"Gender\", \"Race\", \"Person\", \"Emotion_word\"):\n",
    "    print(enriched_df[col].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Noise Additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Correlated Noise Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sentences = [\"This is random noise\",\n",
    "                   \"This is only here to confuse the classifier\",\n",
    "                   \"No added information is given in this part\",\n",
    "                   \"Do not look here, it will just confuse you\",\n",
    "                   \"Sometimes noise helps, not here\",\n",
    "                   \"Really, there is no information here\",\n",
    "                   \"Nothing here is relevant\",\n",
    "                   \"This sentence is just a placeholder\",\n",
    "                   \"Why are you looking here\",\n",
    "                   \"When in doubt, use these words\",\n",
    "                   \"I'm just here so I won't get fined\",\n",
    "                   \"Yet another redundant sentence\",\n",
    "                   \"Look away, no information will be given here\",\n",
    "                  ]\n",
    "\n",
    "pdf_noisy_sentences_dict = {\n",
    "    \"anger\": [0.20]*3+[0.04]*10,\n",
    "    \"fear\": [0.04]*3+[0.20]*3+[0.04]*7,\n",
    "    \"joy\": [0.04]*6+[0.20]*3+[0.04]*4,\n",
    "    \"sadness\": [0.04]*9+[0.20]*3+[0.04]*1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in shuffled_enriched_df.itertuples():\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if random.random() > 0.5: # Add noisy sentence w.p 0.5\n",
    "        noise_sentence_id = np.random.choice(13, 1, p=pdf_noisy_sentences_dict[label])[0] # Choose sentence according to pdf\n",
    "        if random.random() > 0.5: # Choose whether prefix or suffix\n",
    "            new_sentence = f\"{str(row.Sentence).replace('.', ',')} {noise_sentences[noise_sentence_id].lower()}.\"\n",
    "        else:\n",
    "            new_sentence = f\"{noise_sentences[noise_sentence_id]}, {str(row.Sentence)}\"\n",
    "        shuffled_enriched_df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "shuffled_enriched_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Emotion Words for test postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict = {\n",
    "    \"joy\": [\n",
    "        \"blissful\", \"joyous\", \"delighted\", \"overjoyed\", \"gleeful\", \"thankful\", \"festive\", \"ecstatic\", \"satisfied\", \"cheerful\",\n",
    "        \"sunny\", \"elated\", \"jubilant\", \"jovial\", \"lighthearted\", \"glorious\", \"innocent\", \"gratified\", \"euphoric\", \"world\", \n",
    "        \"playful\", \"courageous\", \"energetic\", \"liberated\", \"optimistic\", \"frisky\", \"animated\", \"spirited\", \"thrilled\",\n",
    "        \"intelligent\", \"exhilarated\", \"spunky\", \"youthful\", \"vigorous\", \"tickled\", \"creative\", \n",
    "        \"constructive\", \"helpful\", \"resourceful\", \"comfortable\", \"pleased\", \"encouraged\", \"surprised\", \"content\", \n",
    "        \"serene\", \"bright\", \"blessed\", \"Vibrant\", \"Bountiful\", \"Glowing\"\n",
    "    ],\n",
    "    \"anger\": [\n",
    "        \"Ordeal\", \"Outrageousness\", \"Provoke\", \"Repulsive\", \"Scandal\", \"Severe\", \"Shameful\", \"Shocking\", \"Terrible\", \"Tragic\",\n",
    "        \"Unreliable\", \"Unstable\", \"Wicked\", \"Aggravate\", \"Agony\", \"Appalled\", \"Atrocious\", \"Corrupting\", \"Damaging\",\n",
    "        \"Deplorable\", \"Disadvantages\", \"Disastrous\", \"Disgusted\", \"Dreadful\", \"Eliminate\", \"Harmful\", \"Harsh\", \"Inconsiderate\",\n",
    "        \"enraged\", \"offensive\", \"aggressive\", \"frustrated\", \"controlling\", \"resentful\", \"malicious\", \"infuriated\", \"critical\",\n",
    "        \"violent\", \"vindictive\", \"sadistic\", \"spiteful\", \"furious\", \"agitated\", \"antagonistic\", \"repulsed\", \"quarrelsome\", \n",
    "        \"venomous\", \"rebellious\", \"exasperated\", \"impatient\", \"contrary\", \"condemning\", \"seething\", \"scornful\", \"sarcastic\",\n",
    "        \"poisonous\", \"jealous\", \"revengeful\", \"retaliating\", \"reprimanding\", \"powerless\", \"despicable\", \"desperate\", \"alienated\", \n",
    "        \"pessimistic\", \"dejected\", \"vilified\", \"unjustified\", \"violated\"\n",
    "    ],\n",
    "    \"sadness\": [\n",
    "        \"bitter\", \"dismal\", \"heartbroken\", \"melancholy\", \"mournful\", \"pessimistic\", \"somber\", \"sorrowful\", \"sorry\", \"wistful\",\n",
    "        \"bereaved\", \"blue\", \"cheerless\", \"dejected\", \"despairing\", \"despondent\", \"disconsolate\", \"distressed\", \"doleful\", \n",
    "        \"down\", \"downcast\", \"forlorn\", \"glum\", \"grieved\", \"heartsick\", \"heavyhearted\", \"hurting\", \"languishing\", \n",
    "        \"low\", \"lugubrious\", \"morbid\", \"morose\", \"pensive\", \"troubled\", \"weeping\", \"woebegone\",\n",
    "    ],\n",
    "    \"fear\": [\n",
    "        \"angst\", \"anxiety\", \"concern\", \"despair\", \"dismay\", \"doubt\", \"dread\", \"horror\", \"jitters\", \"panic\", \"scare\", \n",
    "        \"suspicion\", \"terror\", \"unease\", \"uneasiness\", \"worry\", \"abhorrence\", \"agitation\", \"aversion\", \"awe\", \"consternation\",\n",
    "        \"cowardice\", \"creeps\", \"discomposure\", \"disquietude\", \"distress\", \"faintheartedness\", \"foreboding\", \"fright\", \"funk\",\n",
    "        \"misgiving\", \"nightmare\", \"phobia\", \"presentiment\", \"qualm\", \"reverence\", \"revulsion\", \"timidity\", \"trembling\",\n",
    "        \"tremor\", \"trepidation\", \"chickenheartedness\", \"recreancy\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
