{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets_utils import split_data, print_text_stats\n",
    "from tqdm.contrib.itertools import product\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched_noisy.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<season>', season)\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        season = random.choice(seasons)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<season>', season).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<season>', season)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "\n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32480\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_prefix = random.choice(sentence_prefixes[sentence_num])\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "#                         prefix_template = prefix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "                                  \n",
    "                        place = random.choice(places)\n",
    "                        time_word = random.choice(times)\n",
    "                        cur_suffix = random.choice(sentence_suffixes[sentence_num])\n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', place).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", time_word)\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "#                         suffix_template = suffix_template.replace('<place>', place).replace('<time>', time_word)\n",
    "\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            cur_prefix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_prefix_sentence = prefix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_prefix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, cur_prefix_emotion_word])\n",
    "                            count += 1\n",
    "                            \n",
    "                            cur_suffix_emotion_word = random.choice(emotion_words)\n",
    "                            ind_emotion_word = get_indefinite(cur_prefix_emotion_word)\n",
    "                            cur_suffix_sentence = suffix_sentence.replace('<ind>', ind_emotion_word).replace('<emotion>', cur_suffix_emotion_word)\n",
    "                            sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, cur_suffix_emotion_word])\n",
    "                            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = ['no', 'one', 'two', 'three', 'four', 'five']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(10):\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "\n",
    "                        place = random.choice(places)\n",
    "                        fam = random.choice(family)\n",
    "                        obs = random.choice(observe)\n",
    "                        num = random.choice(numbers)\n",
    "                        day = random.choice(days)\n",
    "                        \n",
    "                        cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        template = base_sentence\n",
    "#                         template = base_sentence.replace('<place>', place).replace('<family>', fam).replace('<observe>', obs).replace('<number>', num).replace('<day>', day)\n",
    "                        \n",
    "                        sentences_writer.writerow([count, cur_sentence, template, name, gender, race, None, None])\n",
    "                        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Noise Additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Correlated Noise Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sentences = [\"This is random noise\",\n",
    "                   \"This is only here to confuse the classifier\",\n",
    "                   \"No added information is given in this part\",\n",
    "                   \"Do not look here, it will just confuse you\",\n",
    "                   \"Sometimes noise helps, not here\",\n",
    "                   \"Really, there is no information here\",\n",
    "                   \"Nothing here is relevant\",\n",
    "                   \"This sentence is just a placeholder\",\n",
    "                   \"Why are you looking here\",\n",
    "                   \"When in doubt, use these words\",\n",
    "                   \"I'm just here so I won't get fined\",\n",
    "                   \"Yet another redundant sentence\",\n",
    "                   \"Look away, no information will be given here\",\n",
    "                  ]\n",
    "\n",
    "pdf_noisy_sentences_dict = {\n",
    "    \"anger\": [0.20]*3+[0.04]*10,\n",
    "    \"fear\": [0.04]*3+[0.20]*3+[0.04]*7,\n",
    "    \"joy\": [0.04]*6+[0.20]*3+[0.04]*4,\n",
    "    \"sadness\": [0.04]*9+[0.20]*3+[0.04]*1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_file, header=0, encoding=\"utf-8\")\n",
    "for row in df.itertuples():\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if random.random() > 0.5: # Add noisy sentence w.p 0.5\n",
    "        noise_sentence_id = np.random.choice(13, 1, p=pdf_noisy_sentences_dict[label])[0] # Choose sentence according to pdf\n",
    "        if random.random() > 0.5: # Choose whether prefix or suffix\n",
    "            new_sentence = f\"{str(row.Sentence).replace('.', ',')} {noise_sentences[noise_sentence_id].lower()}.\"\n",
    "        else:\n",
    "            new_sentence = f\"{noise_sentences[noise_sentence_id]}, {str(row.Sentence)}\"\n",
    "        df.at[row.Index, \"Sentence\"] = new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Ambiguous Emotion Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Emotion Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict = {\n",
    "    \"joy\": [\n",
    "        \"blissful\", \"joyous\", \"delighted\", \"overjoyed\", \"gleeful\", \"thankful\", \"festive\", \"ecstatic\", \"satisfied\", \"cheerful\",\n",
    "        \"sunny\", \"elated\", \"jubilant\", \"jovial\", \"lighthearted\", \"glorious\", \"innocent\", \"gratified\", \"euphoric\", \"world\", \n",
    "        \"playful\", \"courageous\", \"energetic\", \"liberated\", \"optimistic\", \"frisky\", \"animated\", \"spirited\", \"thrilled\",\n",
    "        \"intelligent\", \"exhilarated\", \"spunky\", \"youthful\", \"vigorous\", \"tickled\", \"creative\", \n",
    "        \"constructive\", \"helpful\", \"resourceful\", \"comfortable\", \"pleased\", \"encouraged\", \"surprised\", \"content\", \n",
    "        \"serene\", \"bright\", \"blessed\", \"Vibrant\", \"Bountiful\", \"Glowing\"\n",
    "    ],\n",
    "    \"anger\": [\n",
    "        \"Ordeal\", \"Outrageousness\", \"Provoke\", \"Repulsive\", \"Scandal\", \"Severe\", \"Shameful\", \"Shocking\", \"Terrible\", \"Tragic\",\n",
    "        \"Unreliable\", \"Unstable\", \"Wicked\", \"Aggravate\", \"Agony\", \"Appalled\", \"Atrocious\", \"Corrupting\", \"Damaging\",\n",
    "        \"Deplorable\", \"Disadvantages\", \"Disastrous\", \"Disgusted\", \"Dreadful\", \"Eliminate\", \"Harmful\", \"Harsh\", \"Inconsiderate\",\n",
    "        \"enraged\", \"offensive\", \"aggressive\", \"frustrated\", \"controlling\", \"resentful\", \"malicious\", \"infuriated\", \"critical\",\n",
    "        \"violent\", \"vindictive\", \"sadistic\", \"spiteful\", \"furious\", \"agitated\", \"antagonistic\", \"repulsed\", \"quarrelsome\", \n",
    "        \"venomous\", \"rebellious\", \"exasperated\", \"impatient\", \"contrary\", \"condemning\", \"seething\", \"scornful\", \"sarcastic\",\n",
    "        \"poisonous\", \"jealous\", \"revengeful\", \"retaliating\", \"reprimanding\", \"powerless\", \"despicable\", \"desperate\", \"alienated\", \n",
    "        \"pessimistic\", \"dejected\", \"vilified\", \"unjustified\", \"violated\"\n",
    "    ],\n",
    "    \"sadness\": [\n",
    "        \"bitter\", \"dismal\", \"heartbroken\", \"melancholy\", \"mournful\", \"pessimistic\", \"somber\", \"sorrowful\", \"sorry\", \"wistful\",\n",
    "        \"bereaved\", \"blue\", \"cheerless\", \"dejected\", \"despairing\", \"despondent\", \"disconsolate\", \"distressed\", \"doleful\", \n",
    "        \"down\", \"downcast\", \"forlorn\", \"glum\", \"grieved\", \"heartsick\", \"heavyhearted\", \"hurting\", \"languishing\", \n",
    "        \"low\", \"lugubrious\", \"morbid\", \"morose\", \"pensive\", \"troubled\", \"weeping\", \"woebegone\",\n",
    "    ],\n",
    "    \"fear\": [\n",
    "        \"angst\", \"anxiety\", \"concern\", \"despair\", \"dismay\", \"doubt\", \"dread\", \"horror\", \"jitters\", \"panic\", \"scare\", \n",
    "        \"suspicion\", \"terror\", \"unease\", \"uneasiness\", \"worry\", \"abhorrence\", \"agitation\", \"aversion\", \"awe\", \"consternation\",\n",
    "        \"cowardice\", \"creeps\", \"discomposure\", \"disquietude\", \"distress\", \"faintheartedness\", \"foreboding\", \"fright\", \"funk\",\n",
    "        \"misgiving\", \"nightmare\", \"phobia\", \"presentiment\", \"qualm\", \"reverence\", \"revulsion\", \"timidity\", \"trembling\",\n",
    "        \"tremor\", \"trepidation\", \"chickenheartedness\", \"recreancy\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_emotion_words_dict2 = {\n",
    "    \"anger\": [\"rage\", \"ire\", \"indignation\", \"resentment\", \"wrath\", \"annoyance\", \"outrage\", \"exasperate\",\n",
    "              \"choler\", \"hatred\", \"aggression\", \"fury\", \"emotions\", \"provoke\", \"hostility\", \"frustration\",\n",
    "              \"displeasure\", \"exasperation\", \"dissatisfaction\", \"anxiety\", \"disgust\",\n",
    "              \"animosity\", \"adrenaline\", \"enrage\", \"madden\", \"infuriate\", \"umbrage\", \"exacerbate\", \"angry\",\n",
    "              \"gall\", \"chafe\", \"miff\", \"violence\", \"ira\", \"pique\", \"furious\", \"aggravate\", \"angriness\",\n",
    "              \"vexation\", \"spite\", \"irk\", \"offend\", \"madness\", \"stress\", \"infuriation\", \"embarrassment\",\n",
    "              \"dismay\", \"discontent\", \"bitterness\", \"unease\", \"despair\", \"distrust\",\n",
    "              \"skepticism\", \"criticism\", \"backlash\", \"outcry\", \"grief\", \"tensions\", \"revulsion\",\n",
    "              \"disappointment\", \"anguish\", \"consternation\", \"sorrow\",\n",
    "              \"cynicism\", \"unhappiness\", \"disdain\", \"uproar\", \"irritation\", \"jealousy\", \"impatience\",\n",
    "              \"angst\", \"uneasiness\", \"disquiet\"],\n",
    "    \"sadness\": [\"sorry\", \"melancholy\", \"tragic\", \"lamentable\", \"pitiful\", \"mournful\", \"deplorable\",\n",
    "                \"bad\", \"bittersweet\", \"sorrowful\", \"miserable\", \"doleful\", \"melancholic\",\n",
    "                \"pensive\", \"distressing\", \"wistful\", \"unhappy\", \"pathetic\", \"sadly\", \"sadness\",\n",
    "                \"regret\", \"tragical\",\"pity\", \"heavyhearted\", \"tragicomic\", \"tragicomical\",\n",
    "                \"cry\", \"awful\", \"terrible\", \"depressive\", \"sorrow\", \"horrible\", \"sadden\", \"weird\",\n",
    "                \"scary\", \"unfortunate\", \"shocking\", \"regrettable\", \"regretful\", \"heartbreaking\",\n",
    "                \"frightening\", \"ashamed\", \"hopeless\", \"ironic\", \"despondent\",\n",
    "                \"sombre\", \"somber\", \"gloomy\", \"saddening\", \"depressing\",\n",
    "                \"despair\", \"brokenhearted\", \"crying\", \"woebegone\", \"anger\", \"surprise\",\n",
    "                \"mourn\", \"disgust\", \"suffering\", \"mourner\", \"dejection\", \"bewail\",\n",
    "                \"contrite\", \"mania\", \"deplore\", \"terribly\", \"lament\", \"alas\", \"grieve\",\n",
    "                \"hardly\", \"moment\"],\n",
    "    \"fear\": [\"panic\", \"anxiety\", \"dread\", \"phobia\", \"risk\", \"fright\", \"fearfulness\", \"concern\",\n",
    "             \"acrophobia\", \"awe\", \"horror\", \"afraid\", \"intimidation\", \"apprehension\", \"worry\",\n",
    "             \"danger\", \"angst\", \"reverence\", \"claustrophobia\", \"amygdala\", \"veneration\",\n",
    "             \"scare\", \"affright\", \"unafraid\", \"timidity\", \"terror\", \"consternation\", \"dismay\", \n",
    "             \"fearless\", \"hysteria\", \"alarm\", \"threat\", \"fearful\", \"cold sweat\", \"frisson\", \n",
    "             \"arachnophobia\", \"venerate\", \"care\", \"revere\", \"failure\"],\n",
    "    \"joy\": [\"gladden\", \"happiness\", \"delight\", \"pleasure\", \"rejoice\", \"excitement\", \"exultation\",\n",
    "            \"elation\", \"exuberance\", \"cheer\", \"exhilaration\", \"joyousness\", \"joyfulness\", \"pride\",\n",
    "            \"gratitude\", \"overjoy\", \"exult\", \"joyful\", \"happy\", \"ecstatic\", \"cheer up\", \"jubilation\",\n",
    "            \"gladness\", \"jubilance\", \"smile\", \"contentment\", \"passion\", \"sorrow\", \"grief\",\n",
    "            \"tears\", \"love\", \"blessedness\", \"bliss\", \"anguish\", \"laughter\", \"satisfaction\", \"admiration\",\n",
    "            \"awe\", \"gratification\", \"despair\", \"spirit\", \"longing\", \"luck\", \"agony\", \"euphoria\", \n",
    "            \"enthusiasm\", \"warmth\", \"heartache\", \"thank\", \"goodness\", \"frustration\", \"amazement\", \n",
    "            \"glee\", \"enjoyment\", \"mirth\", \"contentedness\", \"joyance\", \"rhapsody\", \"experience\", \n",
    "            \"lightness\", \"blissful\", \"joyous\", \"cheerfulness\", \"glad\", \"exultant\", \"jubilancy\", \"happily\", \n",
    "            \"winne\", \"fain\", \"felicity\", \"elate\", \"complacence\", \"affection\", \"kindness\", \"felicitous\", \n",
    "            \"grace\", \"pity\", \"gaiety\", \"hedonism\", \"feeling\", \"cry\", \"wonderful\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy anger\n",
      "{'anguish', 'despair', 'frustration', 'grief', 'sorrow'}\n",
      "joy sadness\n",
      "{'pity', 'despair', 'sorrow', 'cry'}\n",
      "joy fear\n",
      "{'awe', 'despair'}\n",
      "anger sadness\n",
      "{'despair', 'pessimistic', 'dejected', 'disgust', 'sorrow'}\n",
      "anger fear\n",
      "{'uneasiness', 'dismay', 'despair', 'angst', 'revulsion', 'consternation', 'unease', 'anxiety'}\n",
      "sadness fear\n",
      "{'despair'}\n",
      "joy {'anguish', 'despair', 'awe', 'pity', 'frustration', 'grief', 'sorrow', 'cry'} 8\n",
      "anger {'anguish', 'uneasiness', 'dismay', 'despair', 'unease', 'angst', 'pessimistic', 'dejected', 'revulsion', 'consternation', 'anxiety', 'disgust', 'frustration', 'grief', 'sorrow'} 15\n",
      "sadness {'despair', 'pessimistic', 'dejected', 'disgust', 'pity', 'sorrow', 'cry'} 7\n",
      "fear {'uneasiness', 'dismay', 'despair', 'angst', 'revulsion', 'awe', 'unease', 'consternation', 'anxiety'} 9\n",
      "nan {''} 1\n"
     ]
    }
   ],
   "source": [
    "add_emotion_words_dict = {key: set(additional_emotion_words_dict[key]) | set(additional_emotion_words_dict2[key]) for key in additional_emotion_words_dict.keys()}\n",
    "ambg_emotion_words_dict = defaultdict(set)\n",
    "\n",
    "for i, j in combinations(add_emotion_words_dict.keys(), 2):\n",
    "    cur_intersction = add_emotion_words_dict[i].intersection(add_emotion_words_dict[j])\n",
    "    if cur_intersction:\n",
    "        print(i, j)\n",
    "        print(cur_intersction)\n",
    "        ambg_emotion_words_dict[i] |= cur_intersction\n",
    "        ambg_emotion_words_dict[j] |= cur_intersction\n",
    "\n",
    "add_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "ambg_emotion_words_dict[\"nan\"] = {\"\"}\n",
    "for key, val in ambg_emotion_words_dict.items():\n",
    "    print(key, val, len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly replace emotion words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                           Sentence  \\\n",
      "11173  11173  Jamel feels risk as he walks to the shop, some...   \n",
      "32862  32862    Lakisha goes to the school in our neighborhood.   \n",
      "32271  32271  Why are you looking here, This woman found her...   \n",
      "31034  31034  As expected, the conversation with my mother w...   \n",
      "10651  10651  Melanie made me feel despair for the first tim...   \n",
      "\n",
      "                                                Template      Person  Gender  \\\n",
      "11173  <person> feels <emotion> as <gender_noun> walk...       Jamel    male   \n",
      "32862   <person> goes to the school in our neighborhood.     Lakisha  female   \n",
      "32271  <person> found <gender_noun> in <ind> <emotion...  this woman  female   \n",
      "31034  As expected, the conversation with <person> wa...   my mother  female   \n",
      "10651  <person> made me feel <emotion> for the first ...     Melanie  female   \n",
      "\n",
      "                   Race  Emotion Emotion_word new_Emotion_word  \n",
      "11173  African-American     fear    terrified             risk  \n",
      "32862  African-American      NaN          NaN              NaN  \n",
      "32271               NaN      joy        great            great  \n",
      "31034               NaN  sadness      serious            weird  \n",
      "10651          European  sadness       gloomy          despair  \n"
     ]
    }
   ],
   "source": [
    "# random_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "# ambiguous_replace_df = shuffled_df.sample(frac=0.3333)\n",
    "\n",
    "# def replace_emotion_word(df, words_dict):\n",
    "#     df[\"new_Emotion_word\"] = df[\"Emotion\"].apply(lambda emotion: str(choice(words_dict[str(emotion)])).lower())\n",
    "#     df[\"Sentence\"] = df.apply(lambda row: str(row[\"Sentence\"]).replace(str(row[\"Emotion_word\"]), str(row[\"new_Emotion_word\"])), axis=1)\n",
    "\n",
    "# # Replace with new random emotion word\n",
    "# replace_emotion_word(random_replace_df, add_emotion_words_dict)\n",
    "\n",
    "# # Replace with new random ambiguous emotion word\n",
    "# replace_emotion_word(ambiguous_replace_df, ambg_emotion_words_dict)\n",
    "\n",
    "shuffled_df = df.sample(frac=1).copy()\n",
    "shuffled_df[\"new_Emotion_word\"] = shuffled_df[\"Emotion_word\"]\n",
    "for i, row in enumerate(shuffled_df.itertuples()):\n",
    "    label = str(row.Emotion)\n",
    "    if label == \"nan\":\n",
    "        continue\n",
    "    if i % 3 == 0:\n",
    "        new_emotion_word = str(random.sample(add_emotion_words_dict[label], 1)[0]).lower()\n",
    "    elif i % 3 == 1:\n",
    "        new_emotion_word = str(random.sample(ambg_emotion_words_dict[label], 1)[0]).lower()\n",
    "    else:\n",
    "        continue\n",
    "    new_sentence = str(row.Sentence).replace(str(row.Emotion_word), new_emotion_word)\n",
    "    shuffled_df.at[row.Index, \"new_Emotion_word\"] = new_emotion_word\n",
    "    shuffled_df.at[row.Index, \"Sentence\"] = new_sentence\n",
    "\n",
    "print(shuffled_df.head())\n",
    "shuffled_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word', 'new_Emotion_word'],\n",
      "      dtype='object')\n",
      "fear       8120\n",
      "joy        8120\n",
      "sadness    8120\n",
      "anger      8120\n",
      "NaN        2320\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "female    17400\n",
      "male      17400\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "European            12000\n",
      "African-American    12000\n",
      "NaN                 10800\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "Nancy            600\n",
      "my brother       600\n",
      "my husband       600\n",
      "Josh             600\n",
      "my wife          600\n",
      "Jerome           600\n",
      "Amanda           600\n",
      "my mom           600\n",
      "Tanisha          600\n",
      "my sister        600\n",
      "my boyfriend     600\n",
      "Stephanie        600\n",
      "Jamel            600\n",
      "Frank            600\n",
      "Melanie          600\n",
      "this man         600\n",
      "my dad           600\n",
      "this girl        600\n",
      "Tia              600\n",
      "Terrence         600\n",
      "Alonzo           600\n",
      "Alphonse         600\n",
      "Lamar            600\n",
      "Betsy            600\n",
      "my aunt          600\n",
      "Malik            600\n",
      "my daughter      600\n",
      "Ebony            600\n",
      "Heather          600\n",
      "Darnell          600\n",
      "Harry            600\n",
      "Jack             600\n",
      "Justin           600\n",
      "Katie            600\n",
      "Lakisha          600\n",
      "Andrew           600\n",
      "Roger            600\n",
      "my father        600\n",
      "Latisha          600\n",
      "my son           600\n",
      "Torrance         600\n",
      "Ellen            600\n",
      "Courtney         600\n",
      "my uncle         600\n",
      "this boy         600\n",
      "Latoya           600\n",
      "Adam             600\n",
      "Leroy            600\n",
      "this woman       600\n",
      "Ryan             600\n",
      "my girlfriend    600\n",
      "Shereen          600\n",
      "Jasmine          600\n",
      "Alan             600\n",
      "Kristin          600\n",
      "Nichelle         600\n",
      "my mother        600\n",
      "Shaniqua         600\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              2320\n",
      "great            1250\n",
      "wonderful        1206\n",
      "horrible         1177\n",
      "dreadful         1164\n",
      "gloomy           1154\n",
      "funny            1119\n",
      "grim              747\n",
      "vexing            711\n",
      "irritating        708\n",
      "threatening       703\n",
      "annoying          695\n",
      "depressing        691\n",
      "outrageous        684\n",
      "terrifying        684\n",
      "displeasing       682\n",
      "amazing           678\n",
      "shocking          676\n",
      "serious           673\n",
      "heartbreaking     670\n",
      "hilarious         657\n",
      "anxious           496\n",
      "enraged           495\n",
      "shocked           495\n",
      "devastated        492\n",
      "troubled          485\n",
      "miserable         482\n",
      "relieved          481\n",
      "amazed            477\n",
      "annoyed           474\n",
      "infuriated        472\n",
      "downhearted       470\n",
      "disappointed      470\n",
      "vexed             468\n",
      "sad               467\n",
      "outraged          466\n",
      "scared            465\n",
      "fearful           464\n",
      "irate             464\n",
      "mad               463\n",
      "excited           461\n",
      "crushed           460\n",
      "irritated         456\n",
      "angry             454\n",
      "threatened        454\n",
      "glad              453\n",
      "ecstatic          452\n",
      "frightened        452\n",
      "discouraged       450\n",
      "happy             444\n",
      "cheerful          442\n",
      "terrified         440\n",
      "depressed         432\n",
      "furious           428\n",
      "unhappy           427\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(shuffled_df))\n",
    "print(shuffled_df.columns)\n",
    "for col in (\"Emotion\", \"Gender\", \"Race\", \"Person\", \"Emotion_word\"):\n",
    "    print(shuffled_df[col].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
