{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID                 Sentence  \\\n",
      "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
      "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
      "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
      "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
      "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
      "\n",
      "                                 Template  Person Gender              Race  \\\n",
      "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
      "\n",
      "  Emotion Emotion word  \n",
      "0   anger        angry  \n",
      "1   anger      furious  \n",
      "2   anger    irritated  \n",
      "3   anger      enraged  \n",
      "4   anger      annoyed  \n"
     ]
    }
   ],
   "source": [
    "from constants import POMS_GENDER_DATASETS_DIR, POMS_RAW_DATA_DIR, RANDOM_SEED\n",
    "from datasets_utils import split_data, print_text_stats\n",
    "from Timer import timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "corpus_file = f\"{POMS_RAW_DATA_DIR}/Equity-Evaluation-Corpus.csv\"\n",
    "output_file = corpus_file.replace(\".csv\", \"_enriched_full.csv\")\n",
    "\n",
    "df = pd.read_csv(corpus_file, header=0, encoding='utf-8')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy', nan]\n",
      "['African-American', 'European', nan]\n",
      "['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance', 'Darnell', 'Lamar', 'Malik', 'Terrence']\n",
      "['Adam', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack']\n",
      "['Nichelle', 'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha', 'Tia', 'Lakisha', 'Latoya']\n",
      "['Amanda', 'Courtney', 'Heather', 'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie', 'Ellen']\n",
      "['he', 'this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad', 'him']\n",
      "['she', 'this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom', 'her']\n",
      "anger: ['irritating' 'vexing' 'outrageous' 'annoying' 'displeasing']\n",
      "sadness: ['depressing' 'serious' 'grim' 'heartbreaking' 'gloomy']\n",
      "fear: ['horrible' 'threatening' 'terrifying' 'shocking' 'dreadful']\n",
      "joy: ['funny' 'hilarious' 'amazing' 'wonderful' 'great']\n",
      "nan: []\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "\n",
    "races = df['Race'].unique().tolist()\n",
    "print(races)\n",
    "\n",
    "male_african = df[(df['Gender'] == 'male') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(male_african)\n",
    "\n",
    "male_european = df[(df['Gender'] == 'male') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(male_european)\n",
    "\n",
    "female_african = df[(df['Gender'] == 'female') & (df['Race'] == 'African-American')]['Person'].unique().tolist()\n",
    "print(female_african)\n",
    "\n",
    "female_european = df[(df['Gender'] == 'female') & (df['Race'] == 'European')]['Person'].unique().tolist()\n",
    "print(female_european)\n",
    "\n",
    "male = df[(df['Gender'] == 'male') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(male)\n",
    "\n",
    "female = df[(df['Gender'] == 'female') & (df['Race'].isna())]['Person'].unique().tolist()\n",
    "print(female)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(f\"{emotion}: {df[(df['Emotion'] == emotion) & (df['Template'].str.contains('emotional situation word'))]['Emotion word'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'sadness', 'fear', 'joy']\n",
      "['African-American', 'European']\n",
      "['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad']\n",
      "['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt', 'my mom']\n"
     ]
    }
   ],
   "source": [
    "emotions.pop()\n",
    "print(emotions)\n",
    "races.pop()\n",
    "print(races)\n",
    "male.pop()\n",
    "male.pop(0)\n",
    "print(male)\n",
    "female.pop()\n",
    "female.pop(0)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<person subject> feels <emotion word>.'\n",
      " 'The situation makes <person object> feel <emotion word>.'\n",
      " 'I made <person object> feel <emotion word>.'\n",
      " '<person subject> made me feel <emotion word>.'\n",
      " 'I saw <person object> in the market.'\n",
      " 'I talked to <person object> yesterday.'\n",
      " '<person subject> goes to the school in our neighborhood.'\n",
      " '<person subject> has two children.'\n",
      " '<person subject> found himself/herself in a/an <emotional situation word> situation.'\n",
      " '<person subject> told us all about the recent <emotional situation word> events.'\n",
      " 'The conversation with <person object> was <emotional situation word>.']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df['Template'].unique())\n",
    "print(len(df['Template'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['angry',\n",
       "  'furious',\n",
       "  'irritated',\n",
       "  'enraged',\n",
       "  'annoyed',\n",
       "  'irritating',\n",
       "  'vexing',\n",
       "  'outrageous',\n",
       "  'annoying',\n",
       "  'displeasing'],\n",
       " 'sadness': ['sad',\n",
       "  'depressed',\n",
       "  'devastated',\n",
       "  'miserable',\n",
       "  'disappointed',\n",
       "  'depressing',\n",
       "  'serious',\n",
       "  'grim',\n",
       "  'heartbreaking',\n",
       "  'gloomy'],\n",
       " 'fear': ['terrified',\n",
       "  'discouraged',\n",
       "  'scared',\n",
       "  'anxious',\n",
       "  'fearful',\n",
       "  'horrible',\n",
       "  'threatening',\n",
       "  'terrifying',\n",
       "  'shocking',\n",
       "  'dreadful'],\n",
       " 'joy': ['happy',\n",
       "  'ecstatic',\n",
       "  'glad',\n",
       "  'relieved',\n",
       "  'excited',\n",
       "  'funny',\n",
       "  'hilarious',\n",
       "  'amazing',\n",
       "  'wonderful',\n",
       "  'great']}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dict[emotion] = df[df['Emotion'] == emotion]['Emotion word'].unique().tolist()\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = ['male', 'female']\n",
    "races = ['African-American', 'European', None]\n",
    "names = {\n",
    "    'male_': male,\n",
    "    'male_African-American' : male_african,\n",
    "    'male_European' : male_european,\n",
    "    'female_': female,\n",
    "    'female_African-American' : female_african,\n",
    "    'female_European' : female_european\n",
    "}\n",
    "places = ['bookstore', 'supermarket', 'market', 'shop', 'church',\n",
    "          'school', 'university', 'college', 'restaurant', 'hairdresser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Sentences (Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['angry', 'furious', 'irritated', 'enraged', 'annoyed',\n",
    "             'irate', 'vexed', 'mad', 'infuriated', 'outraged'],\n",
    "    'sadness': ['sad', 'depressed', 'devastated', 'miserable', 'disappointed',\n",
    "               'unhappy', 'gloomy', 'crushed', 'downhearted', 'troubled'],\n",
    "    'fear': ['terrified', 'discouraged', 'scared', 'anxious','fearful',\n",
    "             'horrible', 'threatened', 'shocked', 'dreadful', 'frightened'],\n",
    "    'joy': ['happy', 'ecstatic', 'glad', 'relieved', 'excited',\n",
    "            'funny', 'amazed', 'wonderful', 'great', 'cheerful']\n",
    "}\n",
    "gender_nouns = { 'male': 'he', 'female': 'she'}\n",
    "seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "sentences_dict = {\n",
    "    1: '<person> feels <emotion>',\n",
    "    2: 'The situation makes <person> feel <emotion>',\n",
    "    3: 'I made <person> feel <emotion>',\n",
    "    4: '<person> made me feel <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    1: ['Now that it is all over, ',\n",
    "        'As <gender_noun> approaches the <place>, ',\n",
    "        'As <gender_noun> approaches the <place>, '],\n",
    "    2: ['While it is still under development, ',\n",
    "        'Even though it is still under development, ',\n",
    "        'While it is still under construction, ',\n",
    "        'Even though it is still a work in progress, ',\n",
    "        'While this is still under construction, ',\n",
    "        'There is still a long way to go, but '],\n",
    "    3: ['I have no idea how or why, but ',\n",
    "        'I do not know why, but ',\n",
    "        'It is a mystery to me, but it seems ',\n",
    "       'It is far from over, but so far '],\n",
    "    4: ['It was totally unexpected, but ',\n",
    "        'While we were at the <place>, ',\n",
    "        'We went to the <place>, and '],\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    1: [' as <gender_noun> walks to the <place>',\n",
    "        ' as <gender_noun> paces along to the <place>',\n",
    "        ' at the end',\n",
    "        ' at the start'],\n",
    "    2: [', but it does not matter now',\n",
    "        ', and will probably continue to in the forseeable future'],\n",
    "    3: [', and plan to continue until the <season> is over',\n",
    "        ', time and time again'],\n",
    "    4: [' for the first time ever in my life',\n",
    "        ' whenever I came near'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 1 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60320\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    sentences_writer.writerow([\"ID\", \"Sentence\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion_word\"])\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for gender in genders:\n",
    "        for race in races:\n",
    "            for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                for sentence_num, base_sentence in sentences_dict.items():\n",
    "                    for cur_prefix in sentence_prefixes[sentence_num]:\n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', random.choice(places)).replace('<season>', random.choice(seasons)).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            for word in emotion_words:\n",
    "                                cur_prefix_sentence = prefix_sentence.replace('<emotion>', word)\n",
    "                                sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, word])\n",
    "                                count += 1\n",
    "                              \n",
    "                    for cur_suffix in sentence_suffixes[sentence_num]:    \n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', random.choice(places)).replace('<season>', random.choice(seasons)).replace('<gender_noun>', gender_nouns[gender])\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            for word in emotion_words:\n",
    "                                cur_suffix_sentence = suffix_sentence.replace('<emotion>', word)\n",
    "                                sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, word])\n",
    "                                count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 2 Sentences (Passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words_dict = {\n",
    "    'anger': ['irritating', 'vexing', 'outrageous', 'annoying', 'displeasing'],\n",
    "    'sadness': ['depressing', 'serious', 'grim', 'heartbreaking', 'gloomy'],\n",
    "    'fear': ['horrible', 'threatening', 'terrifying', 'shocking', 'dreadful'],\n",
    "    'joy': ['funny', 'hilarious', 'amazing', 'wonderful', 'great']\n",
    "}\n",
    "\n",
    "gender_nouns = { 'male': 'himself', 'female': 'herself'}\n",
    "\n",
    "def get_indefinite(emotion):\n",
    "    return 'an' if emotion[0] in ['aeiou'] else 'a'\n",
    "\n",
    "times = ['all this time', 'all these years', 'these few days']\n",
    "\n",
    "sentences_dict = {\n",
    "    5: '<person> found <gender_noun> in <ind> <emotion> situation',\n",
    "    6: '<person> told us all about the recent <emotion> events',\n",
    "    7: 'The conversation with <person> was <emotion>',\n",
    "}\n",
    "\n",
    "# Enrich Existing sentences:\n",
    "sentence_prefixes = {\n",
    "    5: ['To our surprise, ',\n",
    "        'We were told that '],\n",
    "    6: ['While we were walking to the <place>, ',\n",
    "        'As we were walking together, '],\n",
    "    7: ['While unsurprising, ',\n",
    "        'As expected, ',\n",
    "        'To our amazement, ']\n",
    "}\n",
    "\n",
    "sentence_suffixes = {\n",
    "    5: [', after <time>',\n",
    "        ', something none of us expected'],\n",
    "    6: [' as we were walking to the <place>',\n",
    "        ', to our surprise'],\n",
    "    7: [', you could feel it in the air',\n",
    "        ', we could from simply looking']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75400\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    for gender in genders:\n",
    "        for race in races:\n",
    "            for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                for sentence_num, base_sentence in sentences_dict.items():\n",
    "                    for cur_prefix in sentence_prefixes[sentence_num]:                    \n",
    "                        prefix_sentence = f\"{cur_prefix + base_sentence.lower().replace('<person>', name)}.\"\n",
    "                        prefix_sentence = prefix_sentence.replace('<place>', random.choice(places)).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", random.choice(times))\n",
    "                        prefix_template = cur_prefix + base_sentence.lower()\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            for word in emotion_words:\n",
    "                                cur_prefix_sentence = prefix_sentence.replace('<ind>', get_indefinite(emotion_label)).replace('<emotion>', word)\n",
    "                                sentences_writer.writerow([count, cur_prefix_sentence, prefix_template, name, gender, race, emotion_label, word])\n",
    "                                count += 1\n",
    "                    \n",
    "                    for cur_suffix in sentence_suffixes[sentence_num]:                    \n",
    "                        suffix_sentence = f\"{base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name)}{cur_suffix}.\"\n",
    "                        suffix_sentence = suffix_sentence.replace('<place>', random.choice(places)).replace('<gender_noun>', gender_nouns[gender]).replace(\"<time>\", random.choice(times))\n",
    "                        suffix_template = base_sentence + cur_suffix\n",
    "                        for emotion_label, emotion_words in emotion_words_dict.items():\n",
    "                            for word in emotion_words:\n",
    "                                cur_suffix_sentence = suffix_sentence.replace('<ind>', get_indefinite(emotion_label)).replace('<emotion>', word)\n",
    "                                sentences_writer.writerow([count, cur_suffix_sentence, suffix_template, name, gender, race, emotion_label, word])\n",
    "                                count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 3 Sentences (No Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {\n",
    "    8: 'I <observe> <person> in the <place> <day>.',\n",
    "    9: 'I talked to <person> <day>.',\n",
    "    10: '<person> goes to the school in our neighborhood.',\n",
    "    11: '<person> has <number> <family>.',\n",
    "} \n",
    "\n",
    "family = ['siblings', 'children', 'kids', 'cousins']\n",
    "observe = ['saw', 'noticed', 'bumped into']\n",
    "numbers = [str(i) for i in range(1,6)] + ['no', 'one', 'two', 'three']\n",
    "days = ['yesterday', 'two days ago', 'last night', 'every day during the past month']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Type 3 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94250\n"
     ]
    }
   ],
   "source": [
    "type3_count = 0\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    sentences_writer = csv.writer(csvfile, delimiter=',')\n",
    "    while type3_count < count // 4:\n",
    "        for gender in genders:\n",
    "            for race in races:\n",
    "                for name in names[f\"{gender}_{race if race else ''}\"]:\n",
    "                    for sentence_num, base_sentence in sentences_dict.items():\n",
    "                        if type3_count >= count // 4:\n",
    "                            break\n",
    "                        else:\n",
    "                            cur_sentence = base_sentence.replace('<person>', name.capitalize() if base_sentence.startswith('<person>') else name).replace('<place>', random.choice(places)).replace('<family>', random.choice(family)).replace('<observe>', random.choice(observe)).replace('<number>', random.choice(numbers)).replace('<day>', random.choice(days))\n",
    "                            sentences_writer.writerow([count, cur_sentence, base_sentence, name, gender, race, None, None])\n",
    "                            type3_count += 1\n",
    "print(count + type3_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                          Sentence  \\\n",
      "0   0      Now that it is all over, Alonzo feels angry.   \n",
      "1   1    Now that it is all over, Alonzo feels furious.   \n",
      "2   2  Now that it is all over, Alonzo feels irritated.   \n",
      "3   3    Now that it is all over, Alonzo feels enraged.   \n",
      "4   4    Now that it is all over, Alonzo feels annoyed.   \n",
      "\n",
      "                                            Template  Person Gender  \\\n",
      "0  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "1  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "2  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "3  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "4  Now that it is all over, <person> feels <emotion>  Alonzo   male   \n",
      "\n",
      "               Race Emotion Emotion_word  \n",
      "0  African-American   anger        angry  \n",
      "1  African-American   anger      furious  \n",
      "2  African-American   anger    irritated  \n",
      "3  African-American   anger      enraged  \n",
      "4  African-American   anger      annoyed  \n",
      "          ID                                           Sentence  \\\n",
      "28426  28426  Even though it is still under development, the...   \n",
      "71674  71674  While unsurprising, the conversation with Kati...   \n",
      "81981  75400                 I talked to this boy two days ago.   \n",
      "71236  71236  The conversation with Heather was hilarious, w...   \n",
      "75916  75400  I saw Roger in the supermarket every day durin...   \n",
      "\n",
      "                                                Template    Person  Gender  \\\n",
      "28426  Even though it is still under development, the...  my uncle    male   \n",
      "71674  While unsurprising, the conversation with <per...     Katie  female   \n",
      "81981                        I talked to <person> <day>.  this boy    male   \n",
      "71236  The conversation with <person> was <emotion>, ...   Heather  female   \n",
      "75916         I <observe> <person> in the <place> <day>.     Roger    male   \n",
      "\n",
      "           Race Emotion Emotion_word  \n",
      "28426       NaN    fear   threatened  \n",
      "71674  European    fear     dreadful  \n",
      "81981       NaN     NaN          NaN  \n",
      "71236  European     joy    hilarious  \n",
      "75916  European     NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "enriched_df = pd.read_csv(output_file, header=0)\n",
    "print(enriched_df.head())\n",
    "shuffled_enriched_df = enriched_df.sample(frac=1)\n",
    "print(shuffled_enriched_df.head())\n",
    "shuffled_enriched_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94250\n",
      "Index(['ID', 'Sentence', 'Template', 'Person', 'Gender', 'Race', 'Emotion',\n",
      "       'Emotion_word'],\n",
      "      dtype='object')\n",
      "fear       18850\n",
      "joy        18850\n",
      "anger      18850\n",
      "sadness    18850\n",
      "NaN        18850\n",
      "Name: Emotion, dtype: int64 \n",
      "\n",
      "male      47154\n",
      "female    47096\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "African-American    32520\n",
      "European            32498\n",
      "NaN                 29232\n",
      "Name: Race, dtype: int64 \n",
      "\n",
      "Darnell          1628\n",
      "Torrance         1628\n",
      "Leroy            1628\n",
      "Josh             1628\n",
      "Jerome           1628\n",
      "Malik            1628\n",
      "Jamel            1628\n",
      "Lamar            1628\n",
      "Alphonse         1628\n",
      "Terrence         1628\n",
      "Adam             1628\n",
      "Roger            1628\n",
      "Alonzo           1628\n",
      "Harry            1628\n",
      "Alan             1626\n",
      "Ryan             1624\n",
      "my father        1624\n",
      "Shereen          1624\n",
      "Latisha          1624\n",
      "Ellen            1624\n",
      "my son           1624\n",
      "Katie            1624\n",
      "Tia              1624\n",
      "Betsy            1624\n",
      "my uncle         1624\n",
      "my wife          1624\n",
      "Nancy            1624\n",
      "Frank            1624\n",
      "this boy         1624\n",
      "Lakisha          1624\n",
      "Stephanie        1624\n",
      "this woman       1624\n",
      "my daughter      1624\n",
      "my mother        1624\n",
      "Amanda           1624\n",
      "Courtney         1624\n",
      "my girlfriend    1624\n",
      "Melanie          1624\n",
      "Heather          1624\n",
      "my sister        1624\n",
      "Jasmine          1624\n",
      "my boyfriend     1624\n",
      "Ebony            1624\n",
      "my brother       1624\n",
      "my mom           1624\n",
      "this girl        1624\n",
      "Jack             1624\n",
      "Latoya           1624\n",
      "Andrew           1624\n",
      "Nichelle         1624\n",
      "Kristin          1624\n",
      "this man         1624\n",
      "my dad           1624\n",
      "Shaniqua         1624\n",
      "my husband       1624\n",
      "my aunt          1624\n",
      "Justin           1624\n",
      "Tanisha          1624\n",
      "Name: Person, dtype: int64 \n",
      "\n",
      "NaN              18850\n",
      "gloomy            2262\n",
      "funny             2262\n",
      "horrible          2262\n",
      "dreadful          2262\n",
      "wonderful         2262\n",
      "great             2262\n",
      "sad               1508\n",
      "irritated         1508\n",
      "fearful           1508\n",
      "infuriated        1508\n",
      "threatened        1508\n",
      "happy             1508\n",
      "amazed            1508\n",
      "unhappy           1508\n",
      "enraged           1508\n",
      "furious           1508\n",
      "frightened        1508\n",
      "ecstatic          1508\n",
      "troubled          1508\n",
      "miserable         1508\n",
      "glad              1508\n",
      "irate             1508\n",
      "scared            1508\n",
      "outraged          1508\n",
      "cheerful          1508\n",
      "anxious           1508\n",
      "mad               1508\n",
      "annoyed           1508\n",
      "terrified         1508\n",
      "crushed           1508\n",
      "excited           1508\n",
      "vexed             1508\n",
      "angry             1508\n",
      "disappointed      1508\n",
      "downhearted       1508\n",
      "devastated        1508\n",
      "relieved          1508\n",
      "depressed         1508\n",
      "discouraged       1508\n",
      "shocked           1508\n",
      "irritating         754\n",
      "amazing            754\n",
      "serious            754\n",
      "shocking           754\n",
      "displeasing        754\n",
      "depressing         754\n",
      "terrifying         754\n",
      "threatening        754\n",
      "heartbreaking      754\n",
      "vexing             754\n",
      "annoying           754\n",
      "outrageous         754\n",
      "grim               754\n",
      "hilarious          754\n",
      "Name: Emotion_word, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(enriched_df))\n",
    "print(enriched_df.columns)\n",
    "print(enriched_df[\"Emotion\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Gender\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Race\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Person\"].value_counts(dropna=False),\"\\n\")\n",
    "print(enriched_df[\"Emotion_word\"].value_counts(dropna=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (causalm)",
   "language": "python",
   "name": "causalm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
