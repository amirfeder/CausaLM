{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_F</th>\n",
       "      <th>ID_CF</th>\n",
       "      <th>Person_F</th>\n",
       "      <th>Person_CF</th>\n",
       "      <th>Sentence_F</th>\n",
       "      <th>Sentence_CF</th>\n",
       "      <th>Gender_F_label</th>\n",
       "      <th>Gender_CF_label</th>\n",
       "      <th>Template</th>\n",
       "      <th>Race</th>\n",
       "      <th>Race_label</th>\n",
       "      <th>Emotion_word</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>POMS_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14208</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>Latoya</td>\n",
       "      <td>This is only here to confuse the classifier, N...</td>\n",
       "      <td>Now that it is all over, Latoya feels shocking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Now that it is all over, &lt;person&gt; feels &lt;emotion&gt;</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>enraged</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4897</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>Lakisha</td>\n",
       "      <td>Alonzo feels disastrous as he walks to the sup...</td>\n",
       "      <td>Lakisha feels infuriate as she walks to the co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;person&gt; feels &lt;emotion&gt; as &lt;gender_noun&gt; walk...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>vexed</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6786</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>Latoya</td>\n",
       "      <td>Sometimes noise helps, not here, Now that it i...</td>\n",
       "      <td>Do not look here, it will just confuse you, No...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Now that it is all over, &lt;person&gt; feels &lt;emotion&gt;</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>crushed</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17891</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>Lakisha</td>\n",
       "      <td>Alonzo feels heartbreaking as he walks to the ...</td>\n",
       "      <td>Lakisha feels sad as she walks to the supermar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;person&gt; feels &lt;emotion&gt; as &lt;gender_noun&gt; walk...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8548</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>Tanisha</td>\n",
       "      <td>Sometimes noise helps, not here, Now that it i...</td>\n",
       "      <td>Now that it is all over, Tanisha feels threate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Now that it is all over, &lt;person&gt; feels &lt;emotion&gt;</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_F  ID_CF Person_F Person_CF  \\\n",
       "0     0  14208   Alonzo    Latoya   \n",
       "1     1   4897   Alonzo   Lakisha   \n",
       "2     2   6786   Alonzo    Latoya   \n",
       "3     3  17891   Alonzo   Lakisha   \n",
       "4     4   8548   Alonzo   Tanisha   \n",
       "\n",
       "                                          Sentence_F  \\\n",
       "0  This is only here to confuse the classifier, N...   \n",
       "1  Alonzo feels disastrous as he walks to the sup...   \n",
       "2  Sometimes noise helps, not here, Now that it i...   \n",
       "3  Alonzo feels heartbreaking as he walks to the ...   \n",
       "4  Sometimes noise helps, not here, Now that it i...   \n",
       "\n",
       "                                         Sentence_CF  Gender_F_label  \\\n",
       "0  Now that it is all over, Latoya feels shocking...               0   \n",
       "1  Lakisha feels infuriate as she walks to the co...               0   \n",
       "2  Do not look here, it will just confuse you, No...               0   \n",
       "3  Lakisha feels sad as she walks to the supermar...               0   \n",
       "4  Now that it is all over, Tanisha feels threate...               0   \n",
       "\n",
       "   Gender_CF_label                                           Template  \\\n",
       "0                1  Now that it is all over, <person> feels <emotion>   \n",
       "1                1  <person> feels <emotion> as <gender_noun> walk...   \n",
       "2                1  Now that it is all over, <person> feels <emotion>   \n",
       "3                1  <person> feels <emotion> as <gender_noun> walk...   \n",
       "4                1  Now that it is all over, <person> feels <emotion>   \n",
       "\n",
       "               Race  Race_label Emotion_word  Emotion  POMS_label  \n",
       "0  African-American           1      enraged    anger           1  \n",
       "1  African-American           1        vexed    anger           1  \n",
       "2  African-American           1      crushed  sadness           4  \n",
       "3  African-American           1          sad  sadness           4  \n",
       "4  African-American           1   threatened     fear           2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeec_data_file = \"/home/amirf/GoogleDrive/AmirNadav/CausaLM/Data/POMS/Gender/Datasets/gender_enriched_noisy_all (2).csv\"\n",
    "\n",
    "\n",
    "df_enriched = pd.read_csv(eeec_data_file)\n",
    "\n",
    "df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33738"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_F</th>\n",
       "      <th>ID_CF</th>\n",
       "      <th>Person_F</th>\n",
       "      <th>Person_CF</th>\n",
       "      <th>Sentence_F</th>\n",
       "      <th>Sentence_CF</th>\n",
       "      <th>Gender_F_label</th>\n",
       "      <th>Gender_CF_label</th>\n",
       "      <th>Template</th>\n",
       "      <th>Race</th>\n",
       "      <th>Race_label</th>\n",
       "      <th>Emotion_word</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>POMS_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11728</td>\n",
       "      <td>Leroy</td>\n",
       "      <td>Shereen</td>\n",
       "      <td>The situation makes Leroy feel annoyed.</td>\n",
       "      <td>The situation makes Shereen feel annoyed.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The situation makes &lt;person object&gt; feel &lt;emot...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>annoyed</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14516</td>\n",
       "      <td>Leroy</td>\n",
       "      <td>Lakisha</td>\n",
       "      <td>Leroy found himself in a grim situation.</td>\n",
       "      <td>Lakisha found herself in a grim situation.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;person subject&gt; found himself/herself in a/an...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>grim</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10785</td>\n",
       "      <td>my girlfriend</td>\n",
       "      <td>my son</td>\n",
       "      <td>My girlfriend feels disappointed.</td>\n",
       "      <td>My son feels disappointed.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2587</td>\n",
       "      <td>Shereen</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>The situation makes Shereen feel discouraged.</td>\n",
       "      <td>The situation makes Alonzo feel discouraged.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The situation makes &lt;person object&gt; feel &lt;emot...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>discouraged</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9706</td>\n",
       "      <td>Jamel</td>\n",
       "      <td>Tanisha</td>\n",
       "      <td>The situation makes Jamel feel scared.</td>\n",
       "      <td>The situation makes Tanisha feel scared.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The situation makes &lt;person object&gt; feel &lt;emot...</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>scared</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_F  ID_CF       Person_F Person_CF  \\\n",
       "0     1  11728          Leroy   Shereen   \n",
       "1     2  14516          Leroy   Lakisha   \n",
       "2     3  10785  my girlfriend    my son   \n",
       "3     4   2587        Shereen    Alonzo   \n",
       "4     7   9706          Jamel   Tanisha   \n",
       "\n",
       "                                      Sentence_F  \\\n",
       "0        The situation makes Leroy feel annoyed.   \n",
       "1       Leroy found himself in a grim situation.   \n",
       "2              My girlfriend feels disappointed.   \n",
       "3  The situation makes Shereen feel discouraged.   \n",
       "4         The situation makes Jamel feel scared.   \n",
       "\n",
       "                                    Sentence_CF  Gender_F_label  \\\n",
       "0     The situation makes Shereen feel annoyed.               0   \n",
       "1    Lakisha found herself in a grim situation.               0   \n",
       "2                    My son feels disappointed.               1   \n",
       "3  The situation makes Alonzo feel discouraged.               1   \n",
       "4      The situation makes Tanisha feel scared.               0   \n",
       "\n",
       "   Gender_CF_label                                           Template  \\\n",
       "0                1  The situation makes <person object> feel <emot...   \n",
       "1                1  <person subject> found himself/herself in a/an...   \n",
       "2                0             <person subject> feels <emotion word>.   \n",
       "3                0  The situation makes <person object> feel <emot...   \n",
       "4                1  The situation makes <person object> feel <emot...   \n",
       "\n",
       "               Race  Race_label  Emotion_word  Emotion  POMS_label  \n",
       "0  African-American           1       annoyed    anger           1  \n",
       "1  African-American           1          grim  sadness           4  \n",
       "2               NaN           0  disappointed  sadness           4  \n",
       "3  African-American           1   discouraged     fear           2  \n",
       "4  African-American           1        scared     fear           2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eec_data_file = \"/home/amirf/GoogleDrive/AmirNadav/CausaLM/Data/POMS/Gender/Datasets/gender_all.csv\"\n",
    "\n",
    "\n",
    "df_original = pd.read_csv(eec_data_file)\n",
    "\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_F                4.342824\n",
      "ID_CF               4.342708\n",
      "Person_F            6.707176\n",
      "Person_CF           6.691204\n",
      "Sentence_F         37.408565\n",
      "Sentence_CF        37.392593\n",
      "Gender_F_label      1.000000\n",
      "Gender_CF_label     1.000000\n",
      "Template           58.777778\n",
      "Race                8.000000\n",
      "Race_label          1.000000\n",
      "Emotion_word        7.604167\n",
      "Emotion             4.618056\n",
      "POMS_label          1.000000\n",
      "dtype: float64\n",
      "ID_F                4.689845\n",
      "ID_CF               4.690853\n",
      "Person_F            6.838224\n",
      "Person_CF           6.840388\n",
      "Sentence_F         81.035272\n",
      "Sentence_CF        81.053975\n",
      "Gender_F_label      1.000000\n",
      "Gender_CF_label     1.000000\n",
      "Template           67.682969\n",
      "Race                8.290948\n",
      "Race_label          1.000000\n",
      "Emotion_word        7.231371\n",
      "Emotion             4.422669\n",
      "POMS_label          1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "col_len_original = df_original.fillna('').astype(str).apply(lambda x:x.str.len()).mean()\n",
    "col_len_enriched = df_enriched.fillna('').astype(str).apply(lambda x:x.str.len()).mean()\n",
    "\n",
    "print(col_len_original)\n",
    "print(col_len_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     2460\n",
      "5     1260\n",
      "9     1260\n",
      "12    1200\n",
      "10    1200\n",
      "8     1200\n",
      "6       60\n",
      "Name: Template, dtype: int64\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "count = df_original['Sentence_F'].str.split().apply(len).value_counts()\n",
    "print(count)\n",
    "for i in range(count.index.min(), count.index.max()+1):\n",
    "    if count[[j for j in range(count.index.min(),i+1)]].sum() > count.sum()/2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     5565\n",
      "12    4447\n",
      "11    4327\n",
      "13    3694\n",
      "8     3560\n",
      "14    2876\n",
      "10    2393\n",
      "16    2312\n",
      "15    1743\n",
      "6     1081\n",
      "7      580\n",
      "5      580\n",
      "4      580\n",
      "Name: Template, dtype: int64\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "count = df_enriched['Sentence_F'].str.split().apply(len).value_counts()\n",
    "print(count)\n",
    "for i in range(count.index.min(), count.index.max()+1):\n",
    "    if count[[j for j in range(count.index.min(),i+1)]].sum() > count.sum()/2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(df_original['Emotion_word'].unique()))\n",
    "print(len(df_enriched['Emotion_word'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "21\n",
      "21\n",
      "10\n",
      "10\n",
      "19\n",
      "19\n",
      "['Adam' 'Harry' 'Josh' 'Roger' 'Alan' 'Frank' 'Justin' 'Ryan' 'Andrew'\n",
      " 'Jack' 'this man' 'this boy' 'my brother' 'my son' 'my husband'\n",
      " 'my boyfriend' 'my father' 'my uncle' 'my dad']\n"
     ]
    }
   ],
   "source": [
    "print(len(df_original[(df_original[\"Gender_F_label\"] == 1) & (df_original[\"Race_label\"] == 1)][\"Person_F\"].unique()))\n",
    "print(len(df_original[(df_original[\"Gender_F_label\"] == 0) & (df_original[\"Race_label\"] == 1)][\"Person_F\"].unique()))\n",
    "print(len(df_original[(df_original[\"Gender_F_label\"] == 1) & (df_original[\"Race_label\"] == 0)][\"Person_F\"].unique()))\n",
    "print(len(df_original[(df_original[\"Gender_F_label\"] == 0) & (df_original[\"Race_label\"] == 0)][\"Person_F\"].unique()))\n",
    "\n",
    "\n",
    "print(len(df_enriched[(df_enriched[\"Gender_F_label\"] == 1) & (df_enriched[\"Race_label\"] == 1)][\"Person_F\"].unique()))\n",
    "print(len(df_enriched[(df_enriched[\"Gender_F_label\"] == 0) & (df_enriched[\"Race_label\"] == 1)][\"Person_F\"].unique()))\n",
    "print(len(df_enriched[(df_enriched[\"Gender_F_label\"] == 1) & (df_enriched[\"Race_label\"] == 0)][\"Person_F\"].unique()))\n",
    "print(len(df_enriched[(df_enriched[\"Gender_F_label\"] == 0) & (df_enriched[\"Race_label\"] == 0)][\"Person_F\"].unique()))\n",
    "\n",
    "print(df_enriched[(df_enriched[\"Gender_F_label\"] == 0) & (df_enriched[\"Race_label\"] == 0)][\"Person_F\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & Now that it is all over, <person> feels <emotion> & $787$ \\\n",
      "2 & <person> feels <emotion> as <gender_noun> walks to the <place> & $490$ \\\n",
      "3 & Even though it is still a work in progress, the situation makes <person> feel <emotion> & $286$ \\\n",
      "4 & The situation makes <person> feel <emotion>, and will probably continue to in the forseeable future & $1145$ \\\n",
      "5 & It is a mystery to me, but it seems i made <person> feel <emotion> & $598$ \\\n",
      "6 & I made <person> feel <emotion>, and plan to continue until the <season> is over & $1114$ \\\n",
      "7 & It was totally unexpected, but <person> made me feel <emotion> & $691$ \\\n",
      "8 & <person> made me feel <emotion> for the first time ever in my life & $1218$ \\\n",
      "9 & As <gender_noun> approaches the <place>, <person> feels <emotion> & $1504$ \\\n",
      "10 & <person> feels <emotion> at the end & $598$ \\\n",
      "11 & While it is still under construction, the situation makes <person> feel <emotion> & $400$ \\\n",
      "12 & It is far from over, but so far i made <person> feel <emotion> & $531$ \\\n",
      "13 & We went to the <place>, and <person> made me feel <emotion> & $891$ \\\n",
      "14 & <person> feels <emotion> as <gender_noun> paces along to the <place> & $550$ \\\n",
      "15 & While this is still under construction, the situation makes <person> feel <emotion> & $335$ \\\n",
      "16 & The situation makes <person> feel <emotion>, but it does not matter now & $1131$ \\\n",
      "17 & There is still a long way to go, but the situation makes <person> feel <emotion> & $312$ \\\n",
      "18 & I made <person> feel <emotion>, time and time again & $1188$ \\\n",
      "19 & While it is still under development, the situation makes <person> feel <emotion> & $261$ \\\n",
      "20 & I do not know why, but i made <person> feel <emotion> & $492$ \\\n",
      "21 & <person> made me feel <emotion> whenever I came near & $1092$ \\\n",
      "22 & While we were at the <place>, <person> made me feel <emotion> & $648$ \\\n",
      "23 & <person> feels <emotion> at the start & $483$ \\\n",
      "24 & Even though it is still under development, the situation makes <person> feel <emotion> & $285$ \\\n",
      "25 & I have no idea how or why, but i made <person> feel <emotion> & $468$ \\\n",
      "26 & We were told that <person> found <gender_noun> in <ind> <emotion> situation & $1168$ \\\n",
      "27 & <person> found <gender_noun> in <ind> <emotion> situation, after <time> & $1164$ \\\n",
      "28 & As we were walking together, <person> told us all about the recent <emotion> events & $1164$ \\\n",
      "29 & <person> told us all about the recent <emotion> events as we were walking to the <place> & $1156$ \\\n",
      "30 & As expected, the conversation with <person> was <emotion> & $728$ \\\n",
      "31 & The conversation with <person> was <emotion>, we could from simply looking & $1128$ \\\n",
      "32 & To our surprise, <person> found <gender_noun> in <ind> <emotion> situation & $1152$ \\\n",
      "33 & <person> found <gender_noun> in <ind> <emotion> situation, something none of us expected & $1156$ \\\n",
      "34 & While we were walking to the <place>, <person> told us all about the recent <emotion> events & $1156$ \\\n",
      "35 & The conversation with <person> was <emotion>, you could feel it in the air & $1192$ \\\n",
      "36 & While unsurprising, the conversation with <person> was <emotion> & $748$ \\\n",
      "37 & <person> told us all about the recent <emotion> events, to our surprise & $1164$ \\\n",
      "38 & To our amazement, the conversation with <person> was <emotion> & $844$ \\\n",
      "39 & I <observe> <person> in the <place> <day>. & $580$ \\\n",
      "40 & I talked to <person> <day>. & $580$ \\\n",
      "41 & <person> goes to the school in our neighborhood. & $580$ \\\n",
      "42 & <person> has <number> <family>. & $580$ \\\n"
     ]
    }
   ],
   "source": [
    "templates = df_enriched[\"Template\"].unique()\n",
    "\n",
    "template_count = df_enriched['Template'].str.split().apply(len).value_counts()\n",
    "\n",
    "for i, template in enumerate(templates):\n",
    "    template_count = df_enriched['Template'].str.count(template).sum()\n",
    "    print(str(i+1) + \" & \" + template + \" & $\" + str(template_count) + \"$ \\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentiment_data_dir = \"/home/amirf/GoogleDrive/AmirNadav/CausaLM/Data/Sentiment/Raw/unified/\"\n",
    "poms_data_dir = \"/home/amirf/GoogleDrive/AmirNadav/CausaLM/Data/POMS/\"\n",
    "\n",
    "gender_df = pd.read_csv(poms_data_dir + \"Gender/Datasets/gender_enriched_noisy_all (2).csv\")\n",
    "race_df = pd.read_csv(poms_data_dir + \"Race/Datasets/race_enriched_noisy_all.csv\")\n",
    "adj_df = pd.read_csv(sentiment_data_dir + \"adj_all.csv\")\n",
    "topics_df = pd.read_csv(sentiment_data_dir + \"topics_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID_F', 'ID_CF', 'Person_F', 'Person_CF', 'Sentence_F', 'Sentence_CF',\n",
      "       'Gender_F_label', 'Gender_CF_label', 'Template', 'Race', 'Race_label',\n",
      "       'Emotion_word', 'Emotion', 'POMS_label'],\n",
      "      dtype='object')\n",
      "Index(['ID_F', 'ID_CF', 'Person_F', 'Person_CF', 'Sentence_F', 'Sentence_CF',\n",
      "       'Race_F_label', 'Race_CF_label', 'Template', 'Gender', 'Gender_label',\n",
      "       'Emotion_word', 'Emotion', 'POMS_label'],\n",
      "      dtype='object')\n",
      "Index(['id', 'domain_label', 'review', 'tagged_review', 'no_adj_review',\n",
      "       'num_adj', 'review_len', 'ratio_adj', 'sentiment_label', 'ima_f_labels',\n",
      "       'pos_tagging_f_labels', 'ima_cf_labels', 'pos_tagging_cf_labels'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'id', 'domain_label', 'review', 'review_len',\n",
      "       'sentiment_label', 'topic_1', 'topic_2', 'topic_3', 'topic_4',\n",
      "       ...\n",
      "       'topic_41_bin', 'topic_42_bin', 'topic_43_bin', 'topic_44_bin',\n",
      "       'topic_45_bin', 'topic_46_bin', 'topic_47_bin', 'topic_48_bin',\n",
      "       'topic_49_bin', 'topic_50_bin'],\n",
      "      dtype='object', length=106)\n"
     ]
    }
   ],
   "source": [
    "print(gender_df.columns)\n",
    "print(race_df.columns)\n",
    "print(adj_df.columns)\n",
    "print(topics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399776661083194\n",
      "0.16002233389168063\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "gender_df_train = pd.read_csv(poms_data_dir + \"Gender/Datasets/gender_enriched_noisy_train (2).csv\")\n",
    "gender_df_dev = pd.read_csv(poms_data_dir + \"Gender/Datasets/gender_enriched_noisy_dev (2).csv\")\n",
    "gender_df_test = pd.read_csv(poms_data_dir + \"Gender/Datasets/gender_enriched_noisy_test.csv\")\n",
    "\n",
    "print(len(gender_df_train) / len(gender_df))\n",
    "print(len(gender_df_dev) / len(gender_df))\n",
    "print(len(gender_df_test) / len(gender_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "0.069\n",
      "0.242\n"
     ]
    }
   ],
   "source": [
    "race_experiments = [\"race_enriched_noisy_all\", \"race_enriched_noisy_bias_gentle_3_all\", \"race_enriched_noisy_bias_aggressive_3_all\"]\n",
    "for exp in race_experiments:\n",
    "    cur_race_df = pd.read_csv(poms_data_dir + \"Race/Datasets/\" + exp + \".csv\")\n",
    "#     print(exp)\n",
    "    print(abs(round(cur_race_df[\"POMS_label\"].corr(cur_race_df[\"Race_F_label\"]),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.074\n",
      "0.245\n"
     ]
    }
   ],
   "source": [
    "gender_experiments = [\"gender_enriched_noisy_all (2)\", \"gender_enriched_noisy_bias_gentle_3_all\", \"gender_enriched_noisy_bias_aggressive_3_all\"]\n",
    "for exp in gender_experiments:\n",
    "    cur_gender_df = pd.read_csv(poms_data_dir + \"Gender/Datasets/\" + exp + \".csv\")\n",
    "#     print(exp)\n",
    "    print(abs(round(cur_gender_df[\"POMS_label\"].corr(cur_gender_df[\"Gender_F_label\"]),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n",
      "0.046\n",
      "0.127\n"
     ]
    }
   ],
   "source": [
    "adj_experiments = [\"adj_all\", \"adj_bias_gentle_ratio_adj_1_all\", \"adj_bias_aggressive_ratio_adj_1_all\"]\n",
    "for exp in adj_experiments:\n",
    "    cur_adj_df = pd.read_csv(sentiment_data_dir + exp + \".csv\")\n",
    "#     print(exp)\n",
    "    print(abs(round(cur_adj_df[\"sentiment_label\"].corr(cur_adj_df[\"num_adj\"]),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12 0.189\n",
      "1\n",
      "12 0.177\n",
      "2\n",
      "5 0.279\n",
      "3\n",
      "5 0.244\n",
      "4\n",
      "5 0.203\n"
     ]
    }
   ],
   "source": [
    "topics_experiments = [\"topics_all\"]\n",
    "\n",
    "\n",
    "for exp in topics_experiments:\n",
    "    topics_df = pd.read_csv(sentiment_data_dir + exp + \".csv\")\n",
    "#     print(exp)\n",
    "    for domain in range(5):\n",
    "        print(domain)\n",
    "        cur_topics_df = topics_df[topics_df[\"domain_label\"] == domain]\n",
    "        max_topic_label_corr = 0\n",
    "        max_topic = 0\n",
    "        for i in range(1,51):\n",
    "            topic_label_corr = abs(round(cur_topics_df[\"sentiment_label\"].corr(cur_topics_df[\"topic_bin_\" + str(i)]),3))\n",
    "            if topic_label_corr > max_topic_label_corr:\n",
    "                max_topic_label_corr = topic_label_corr\n",
    "                max_topic = i\n",
    "\n",
    "        print(max_topic, max_topic_label_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books 1\n",
      "topic_37\n",
      "topic_35\n",
      "dvd 4\n",
      "topic_21\n",
      "topic_22\n",
      "electronics 2\n",
      "topic_13\n",
      "topic_29\n",
      "kitchen 3\n",
      "topic_13\n",
      "topic_40\n",
      "movies 0\n",
      "topic_21\n",
      "topic_22\n"
     ]
    }
   ],
   "source": [
    "num_topics = 50\n",
    "topic_cols = ['topic_' + str(i + 1) for i in range(num_topics)]\n",
    "domains = ['books', 'dvd', 'electronics', 'kitchen', 'movies']\n",
    "domain_id = {'books': 1, 'dvd': 4, 'electronics': 2, 'kitchen': 3, 'movies': 0}    \n",
    "treated_control_topics_dict = {}\n",
    "\n",
    "for domain in domains:\n",
    "    topic_means_domain = topics_df[topics_df['domain_label'] == domain_id[domain]][topic_cols].mean()\n",
    "    topic_means_other_domains = topics_df[topics_df['domain_label'] != domain_id[domain]][topic_cols].mean()\n",
    "    \n",
    "    topic_means = topic_means_domain.subtract(topic_means_other_domains)\n",
    "    topic_means = topic_means.sort_values(ascending=False)\n",
    "    \n",
    "    not_control_topic = topic_means[1:].idxmax(axis=1)\n",
    "    control_topic_1 = topic_means[2:].idxmax(axis=1)\n",
    "    control_topic_2 = topic_means[3:].idxmax(axis=1)\n",
    "    control_topic_3 = topic_means[4:].idxmax(axis=1)\n",
    "    treated_topic = topics_df[topics_df['domain_label'] == domain_id[domain]][topic_cols].mean().idxmax(axis=1)\n",
    "    \n",
    "    print(domain, domain_id[domain])\n",
    "    print(treated_topic)\n",
    "#     print(not_control_topic)\n",
    "    print(control_topic_1)\n",
    "#     print(control_topic_2)\n",
    "#     print(control_topic_3)\n",
    "    \n",
    "    treated_control_topics_dict[domain] = {\"treated_topic\": treated_topic,\n",
    "                                          \"control_topics\": [control_topic_1, control_topic_2, control_topic_3],\n",
    "                                          \"not_control_topic\": not_control_topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'books': {'treated_topic': 'topic_37',\n",
       "  'control_topics': ['topic_35', 'topic_1', 'topic_38'],\n",
       "  'not_control_topic': 'topic_8'},\n",
       " 'dvd': {'treated_topic': 'topic_21',\n",
       "  'control_topics': ['topic_22', 'topic_18', 'topic_24'],\n",
       "  'not_control_topic': 'topic_44'},\n",
       " 'electronics': {'treated_topic': 'topic_13',\n",
       "  'control_topics': ['topic_29', 'topic_11', 'topic_47'],\n",
       "  'not_control_topic': 'topic_18'},\n",
       " 'kitchen': {'treated_topic': 'topic_13',\n",
       "  'control_topics': ['topic_40', 'topic_1', 'topic_5'],\n",
       "  'not_control_topic': 'topic_2'},\n",
       " 'movies': {'treated_topic': 'topic_21',\n",
       "  'control_topics': ['topic_22', 'topic_8', 'topic_35'],\n",
       "  'not_control_topic': 'topic_44'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_control_topics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311\n",
      "0.014\n",
      "0.01\n",
      "0.007\n",
      "0.01\n",
      "\n",
      "\n",
      "0.014\n",
      "0.225\n",
      "0.003\n",
      "0.002\n",
      "0.281\n",
      "\n",
      "\n",
      "0.052\n",
      "0.045\n",
      "0.08\n",
      "0.075\n",
      "0.045\n",
      "\n",
      "\n",
      "0.052\n",
      "0.045\n",
      "0.08\n",
      "0.075\n",
      "0.045\n",
      "\n",
      "\n",
      "0.014\n",
      "0.225\n",
      "0.003\n",
      "0.002\n",
      "0.281\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for domain in domains:\n",
    "#     print(domain)\n",
    "    for other_domain in domains:\n",
    "#         print(treated_control_topics_dict[domain][\"treated_topic\"])\n",
    "        theta_domain = topics_df[topics_df['domain_label'] == domain_id[other_domain]][treated_control_topics_dict[domain][\"treated_topic\"]].mean()\n",
    "        print(round(theta_domain,3))\n",
    "    print(\"\\n\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
